{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "681fee9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Importing all the relevant library\n",
    "%matplotlib inline\n",
    "import h5py, os\n",
    "#from functions import transforms as T\n",
    "#from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as T\n",
    "import glob\n",
    "#from functions import transforms as T \n",
    "#from functions.subsample import MaskFunc\n",
    "from PIL import Image\n",
    "import random\n",
    "from numpy.fft import fftshift, ifftshift, fftn, ifftn\n",
    "import cmath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5f4d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "raw",
   "id": "5bbd1420",
   "metadata": {},
   "source": [
    "AWS has torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57966d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "\n",
    "class MaskFunc:\n",
    "    \"\"\"\n",
    "    MaskFunc creates a sub-sampling mask of a given shape.\n",
    "\n",
    "    The mask selects a subset of columns from the input k-space data. If the k-space data has N\n",
    "    columns, the mask picks out:\n",
    "        1. N_low_freqs = (N * center_fraction) columns in the center corresponding to\n",
    "           low-frequencies\n",
    "        2. The other columns are selected uniformly at random with a probability equal to:\n",
    "           prob = (N / acceleration - N_low_freqs) / (N - N_low_freqs).\n",
    "    This ensures that the expected number of columns selected is equal to (N / acceleration)\n",
    "\n",
    "    It is possible to use multiple center_fractions and accelerations, in which case one possible\n",
    "    (center_fraction, acceleration) is chosen uniformly at random each time the MaskFunc object is\n",
    "    called.\n",
    "\n",
    "    For example, if accelerations = [4, 8] and center_fractions = [0.08, 0.04], then there\n",
    "    is a 50% probability that 4-fold acceleration with 8% center fraction is selected and a 50%\n",
    "    probability that 8-fold acceleration with 4% center fraction is selected.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, center_fractions, accelerations):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            center_fractions (List[float]): Fraction of low-frequency columns to be retained.\n",
    "                If multiple values are provided, then one of these numbers is chosen uniformly\n",
    "                each time.\n",
    "\n",
    "            accelerations (List[int]): Amount of under-sampling. This should have the same length\n",
    "                as center_fractions. If multiple values are provided, then one of these is chosen\n",
    "                uniformly each time. An acceleration of 4 retains 25% of the columns, but they may\n",
    "                not be spaced evenly.\n",
    "        \"\"\"\n",
    "        if len(center_fractions) != len(accelerations):\n",
    "            raise ValueError('Number of center fractions should match number of accelerations')\n",
    "\n",
    "        self.center_fractions = center_fractions\n",
    "        self.accelerations = accelerations\n",
    "        self.rng = np.random.RandomState()\n",
    "\n",
    "    def __call__(self, shape, seed=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            shape (iterable[int]): The shape of the mask to be created. The shape should have\n",
    "                at least 3 dimensions. Samples are drawn along the second last dimension.\n",
    "            seed (int, optional): Seed for the random number generator. Setting the seed\n",
    "                ensures the same mask is generated each time for the same shape.\n",
    "        Returns:\n",
    "            torch.Tensor: A mask of the specified shape.\n",
    "        \"\"\"\n",
    "        if len(shape) < 3:\n",
    "            raise ValueError('Shape should have 3 or more dimensions')\n",
    "\n",
    "        self.rng.seed(seed)\n",
    "        num_cols = shape[-2]\n",
    "\n",
    "        choice = self.rng.randint(0, len(self.accelerations))\n",
    "        center_fraction = self.center_fractions[choice]\n",
    "        acceleration = self.accelerations[choice]\n",
    "\n",
    "        # Create the mask\n",
    "        num_low_freqs = int(round(num_cols * center_fraction))\n",
    "        prob = (num_cols / acceleration - num_low_freqs) / (num_cols - num_low_freqs)\n",
    "        mask = self.rng.uniform(size=num_cols) < prob\n",
    "        pad = (num_cols - num_low_freqs + 1) // 2\n",
    "        mask[pad:pad + num_low_freqs] = True\n",
    "\n",
    "        # Reshape the mask\n",
    "        mask_shape = [1 for _ in shape]\n",
    "        mask_shape[-2] = num_cols\n",
    "        mask = torch.from_numpy(mask.reshape(*mask_shape).astype(np.float32))\n",
    "\n",
    "        return mask\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0dce273c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fftshift, ifftshift, fftn, ifftn\n",
    "\n",
    "def transform_kspace_to_image(k, dim=None, img_shape=None):\n",
    "    \"\"\" Computes the Fourier transform from k-space to image space\n",
    "    along a given or all dimensions\n",
    "    :param k: k-space data\n",
    "    :param dim: vector of dimensions to transform\n",
    "    :param img_shape: desired shape of output image\n",
    "    :returns: data in image space (along transformed dimensions)\n",
    "    \"\"\"\n",
    "    if not dim:\n",
    "        dim = range(k.ndim)\n",
    "\n",
    "    img = fftshift(ifftn(ifftshift(k, axes=dim), s=img_shape, axes=dim), axes=dim)\n",
    "    #img = fftshift(ifft2(ifftshift(k, dim=dim)), dim=dim)\n",
    "    img *= np.sqrt(np.prod(np.take(img.shape, dim)))\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform_image_to_kspace(img, dim=None, k_shape=None):\n",
    "    \"\"\" Computes the Fourier transform from image space to k-space space\n",
    "    along a given or all dimensions\n",
    "    :param img: image space data\n",
    "    :param dim: vector of dimensions to transform\n",
    "    :param k_shape: desired shape of output k-space data\n",
    "    :returns: data in k-space (along transformed dimensions)\n",
    "    \"\"\"\n",
    "    if not dim:\n",
    "        dim = range(img.ndim)\n",
    "\n",
    "    k = fftshift(fftn(ifftshift(img, axes=dim), s=k_shape, axes=dim), axes=dim)\n",
    "    #k = fftshift(fft2(ifftshift(img, dim=dim)), dim=dim)\n",
    "    k /= np.sqrt(np.prod(np.take(img.shape, dim)))\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1579782d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import random\n",
    "from IPython.display import display\n",
    "\n",
    "\n",
    "def add_noise(array: np.ndarray, dropout_rate: float = 0.10) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function adds noise\n",
    "    :param array:\n",
    "    :param dropout_rate: percent of pixels to be dropped\n",
    "    :return:\n",
    "    \"\"\"\n",
    "   # assert len(array.shape) == 4\n",
    "   # assert array.shape[1] == 3\n",
    "\n",
    "    channels = array.shape[1]\n",
    "    height = array.shape[2]\n",
    "    width = array.shape[3]\n",
    "\n",
    "    total_pixels = height * width\n",
    "    queued_pixels = int(total_pixels * dropout_rate)\n",
    "\n",
    "    filled_pixels = 0\n",
    "    while filled_pixels < queued_pixels:\n",
    "        d_h = random.randint(1, 3)\n",
    "        d_w = random.randint(1, 3)\n",
    "        filled_pixels += d_h * d_w\n",
    "        h = random.randint(0, height - d_h)\n",
    "        w = random.randint(0, width - d_w)\n",
    "\n",
    "        # now overwrite selected pixels with random dark color\n",
    "        array[:, :, h:h+d_h, w:w+d_w] = random.randint(1, 25) / 255.0\n",
    "\n",
    "    return array\n",
    "\n",
    "\n",
    "def array_to_image(array: np.ndarray):\n",
    "    \"\"\"\n",
    "    This function converts NumPy array to image\n",
    "    :param array:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    assert len(array.shape) == 4\n",
    "    assert array.shape[1] == 1 or array.shape[1] == 3\n",
    "\n",
    "    scaled = (array * 255.0).astype(np.uint8)\n",
    "    if array.shape[1] == 1:\n",
    "        reshaped = scaled.reshape((array.shape[2], array.shape[3]))\n",
    "        return Image.fromarray(reshaped,\"L\")\n",
    "    else:\n",
    "        reshaped = scaled.reshape((3, array.shape[2], array.shape[3])).transpose([1, 2, 0])\n",
    "        return Image.fromarray(reshaped,\"RGB\")\n",
    "\n",
    "\n",
    "def image_to_array(image) -> np.ndarray:\n",
    "    \"\"\"\n",
    "    This function converts image to NumPy array\n",
    "    :param image:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    image1 = np.array(image)\n",
    "    return np.expand_dims(np.asarray(image1), 0).astype(np.float) / 255.0\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac2c258c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def show_slices(data, slice_nums, cmap=None): # visualisation\n",
    "    fig = plt.figure(figsize=(15,10))\n",
    "    for i, num in enumerate(slice_nums):\n",
    "        plt.subplot(1, len(slice_nums), i + 1)\n",
    "        plt.imshow(data[num], cmap=cmap)\n",
    "        plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "327d8054",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MRIDataset(DataLoader):\n",
    "    def __init__(self, data_list):\n",
    "        self.data_list = data_list\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_list)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        subject_id = self.data_list[idx]\n",
    "\n",
    "        return get_epoch_batch(subject_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8209b3ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "from numpy.fft import fftshift, ifftshift, fftn, ifftn\n",
    "import cmath\n",
    "def noise_and_kspace(image):\n",
    "    #change to k-space\n",
    "    img_fft = fftshift(fftn(image))\n",
    "    size_img = img_fft.shape\n",
    "     #np.random.uniform, np.random.normal\n",
    "    std = np.random.normal(0.000, 0.005) * np.amax(img_fft)\n",
    "    noise = fftshift(std * np.random.standard_normal(size_img) + std * 1j * np.random.standard_normal(size_img));     #This generates a complex noise signal.\n",
    "    img_fft_noise = img_fft + noise # k-space\n",
    "    img_noise = ifftn(ifftshift(img_fft_noise))# revert k-space back to noise\n",
    "    return img_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "56178edf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_epoch_batch(subject_id):\n",
    "    ''' random select a few slices (batch_size) from each volume'''\n",
    "\n",
    "    fname, rawdata_name = subject_id  \n",
    "    \n",
    "#    with h5py.File(rawdata_name, 'r') as data:\n",
    "#        rawdata = data['kspace'][slice]\n",
    "   \n",
    "    im_frame = Image.open(rawdata_name)\n",
    "    noise_im_frame = noise_and_kspace(im_frame)\n",
    "\n",
    "    ############################\n",
    "    #img_und = to_tensor(np.array(noise_im_frame)).unsqueeze(0) # noise image tensor form    \n",
    "    preprocess = T.Compose([\n",
    "                       # T.Grayscale(num_output_channels=1),\n",
    "                           T.Resize(128),    #128 as maximum #64\n",
    "                           T.CenterCrop(128),\n",
    "                           T.ToTensor() #,\n",
    "                            ])\n",
    "    img_gt = preprocess(Image.fromarray(np.uint8(im_frame)).convert('L'))\n",
    "    img_und = preprocess(Image.fromarray(np.uint8(noise_im_frame)).convert('L'))\n",
    "    \n",
    "    n1 = (img_und**2).sum(dim=-1).sqrt()\n",
    "    norm = n1.max() \n",
    "    if norm < 1e-6: norm = 1e-6\n",
    "    \n",
    "    img_gt, img_und = img_gt/norm , img_und/norm\n",
    "\n",
    "    return img_gt.squeeze(0), img_und.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "575b71b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(train_data_path, val_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_and_val = ['train', 'val']\n",
    "    data_path = [train_data_path, val_data_path]\n",
    "      \n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_and_val[i]] = []\n",
    "        \n",
    "        which_data_path = data_path[i]\n",
    "        tr = 0\n",
    "        te = 0\n",
    "        alfa = 0\n",
    "    \n",
    "        for fname in sorted(os.listdir(which_data_path + '/images')):\n",
    "            if fname == '.DS_Store': continue\n",
    "            \n",
    "            subject_data_path = os.path.join(which_data_path + '/images', fname)\n",
    "                     \n",
    "            if not os.path.isfile(subject_data_path): continue \n",
    "            \n",
    "     \n",
    "            #get information from text file\n",
    "            # this will return a tuple of root and extension\n",
    "            split_tup = os.path.splitext(fname)\n",
    "\n",
    "  \n",
    "            # extract the file name and extension\n",
    "            file_name = split_tup[0]\n",
    "  \n",
    "                \n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "            data_list[train_and_val[i]].append((fname, subject_data_path))\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "raw",
   "id": "b0eeec3b",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "img = imread('IMage Path'); %This is where I read the image matrix\n",
    "img_fft = fftshift(fft2(img));  %change the image to K-Space\n",
    "size_img = size(img_fft); Extract the size matrix for image to create a noise for the same size.\n",
    "\n",
    "%standard deviation decided for the noise. I am using a uniform distribution but you can choose what works best for you.\n",
    "%This noise is with 0 mean and std standard deviation\n",
    "\n",
    "std  = unifrnd(0.000,0.001)*max(img_fft(:,:),[],'all');\n",
    "\n",
    "noise = fftshift(std.*randn(size(img_fft)) + std1.*1i*randn(size(img_fft)));     %This generates a complex noise signal.\n",
    "\n",
    "img_ftt_noise = img_fft + noise;  %Here we add noise to the original image K-Space\n",
    "\n",
    "img_new = ifft2(ifftshift(img_fft));  %This gives you the noise back"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd0961b8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb098708",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "74c35f60",
   "metadata": {},
   "source": [
    "# The initial model, based on the AlexNet architecture"
   ]
  },
  {
   "cell_type": "raw",
   "id": "cfb03fcb-f57e-4c4c-b858-26bfa87a57cf",
   "metadata": {},
   "source": [
    "class AlexNet(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(AlexNet, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(1, 64, kernel_size=3, stride=1, padding=1), #320/320\n",
    "            nn.Dropout2d(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1), #320/320\n",
    "            nn.Dropout2d(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64 ,64, kernel_size=3, padding=1),  # 320/320\n",
    "            nn.Dropout2d(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1), #320/320\n",
    "            nn.Dropout2d(),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),  # 320/320\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Conv2d(64, 1, kernel_size=3, padding=1),  # 320/320\n",
    "            \n",
    "            \n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b87ba",
   "metadata": {},
   "source": [
    "# RestNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957014f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "560bd999",
   "metadata": {},
   "outputs": [],
   "source": [
    "class baseBlock(torch.nn.Module):\n",
    "    expansion = 1\n",
    "    def __init__(self,input_planes,planes,stride=1,dim_change=None):\n",
    "        super(baseBlock,self).__init__()\n",
    "        #declare convolutional layers with batch norms\n",
    "        self.conv1 = torch.nn.Conv2d(input_planes,planes,stride=stride,kernel_size=3,padding=1)\n",
    "        self.bn1   = torch.nn.BatchNorm2d(planes)\n",
    "        self.conv2 = torch.nn.Conv2d(planes,planes,stride=1,kernel_size=3,padding=1)\n",
    "        self.bn2   = torch.nn.BatchNorm2d(planes)\n",
    "        self.dim_change = dim_change\n",
    "    def forward(self,x):\n",
    "        #Save the residue\n",
    "        res = x\n",
    "        output = F.relu(self.bn1(self.conv1(x)))\n",
    "        output = self.bn2(self.conv2(output))\n",
    "        if self.dim_change is not None:\n",
    "            res = self.dim_change(res)\n",
    "        \n",
    "        output += res\n",
    "        output = F.relu(output)\n",
    "\n",
    "        return output\n",
    "\n",
    "class ResNet(torch.nn.Module):\n",
    "    def __init__(self,block,num_layers,classes=10):\n",
    "        super(ResNet,self).__init__()\n",
    "        #according to research paper:\n",
    "        self.input_planes = 64 #256\n",
    "        self.conv1 = torch.nn.Conv2d(1,64,kernel_size=3,stride=1,padding=1)\n",
    "        self.layer1 = self._layer(block,64,num_layers[0],stride=1)\n",
    "        self.layer2 = self._layer(block, 64,num_layers[1],stride=1)\n",
    "        self.layer3 = self._layer(block,64,num_layers[2],stride=1)\n",
    "        self.layer4 = self._layer(block,64,num_layers[3],stride=1)\n",
    "        self.layer5 = self._layer(block,64,num_layers[3],stride=1)\n",
    "        self.layer6 = self._layer(block,64,num_layers[3],stride=1)\n",
    "        self.layer7 = self._layer(block,64,num_layers[3],stride=1)\n",
    "        self.layer8 = self._layer(block,64,num_layers[2],stride=1)\n",
    "     #   self.layer9 = self._layer(block,64,num_layers[3],stride=1)\n",
    "      #  self.layer10 = self._layer(block,64,num_layers[3],stride=1)\n",
    "     #   self.layer11 = self._layer(block,64,num_layers[3],stride=1)\n",
    "     #   self.layer12 = self._layer(block,64,num_layers[3],stride=1)\n",
    "      #  self.layer13 = self._layer(block,64,num_layers[3],stride=1)\n",
    "      #  self.layer14 = self._layer(block,64,num_layers[3],stride=1)\n",
    "      #  self.layer15 = self._layer(block,64,num_layers[3],stride=1)\n",
    "      #  self.layer16 = self._layer(block,64,num_layers[3],stride=1)\n",
    "      #  self.layer17 = self._layer(block,64,num_layers[3],stride=1)\n",
    "      #  self.layer18 = self._layer(block,64,num_layers[3],stride=1)\n",
    "        self.conv2 = torch.nn.Conv2d(64,1,kernel_size=3,stride=1, padding=1)\n",
    "        \n",
    "    \n",
    "    def _layer(self,block,planes,num_layers,stride=1):\n",
    "        dim_change = None\n",
    "        if stride!=1 or planes != self.input_planes*block.expansion:\n",
    "            dim_change = torch.nn.Sequential(torch.nn.Conv2d(self.input_planes,planes*block.expansion,kernel_size=1,stride=stride),\n",
    "                                             torch.nn.BatchNorm2d(planes*block.expansion))\n",
    "        netLayers =[]\n",
    "        netLayers.append(block(self.input_planes,planes,stride=stride,dim_change=dim_change))\n",
    "        self.input_planes = planes * block.expansion\n",
    "        for i in range(1,num_layers):\n",
    "            netLayers.append(block(self.input_planes,planes))\n",
    "            self.input_planes = planes * block.expansion\n",
    "        \n",
    "        return torch.nn.Sequential(*netLayers)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = self.layer4(x)\n",
    "        x = self.layer5(x)\n",
    "        x = self.layer6(x)\n",
    "        x = self.layer7(x)\n",
    "        x = self.layer8(x)\n",
    "     #   x = self.layer9(x)\n",
    "   #     x = self.layer10(x)\n",
    "     #   x = self.layer11(x)\n",
    "      #  x = self.layer12(x)\n",
    "      #  x = self.layer13(x)\n",
    "     #   x = self.layer14(x)\n",
    "      #  x = self.layer15(x)\n",
    "     #   x = self.layer16(x)\n",
    "     #   x = self.layer17(x)\n",
    "     #   x = self.layer18(x)\n",
    "        x = self.conv2(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8195fdba",
   "metadata": {},
   "source": [
    "Changed in version 0.16: This function was renamed from skimage.measure.compare_ssim to skimage.metrics.structural_similarity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6b06b536",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as cmp_ssim \n",
    "from skimage.metrics import mean_squared_error\n",
    "from skimage.metrics import normalized_root_mse\n",
    "def ssim(gt, pred):\n",
    "    \"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"\n",
    "    return cmp_ssim(\n",
    "         gt, pred, multichannel=False, data_range=gt.max()\n",
    "    )\n",
    "#def ssim(gt, pred):\n",
    "#    \"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"\n",
    "#    return cmp_ssim(\n",
    " #       gt.transpose(1, 2, 0), pred.transpose(1, 2, 0), multichannel=True, data_range=gt.max()\n",
    " #   )\n",
    "def mse(gt, pred):\n",
    "    \"\"\" Compute mean squared error. \"\"\"\n",
    "    return mean_squared_error(gt, pred)\n",
    "\n",
    "def nrmse(gt, pred):\n",
    "    \"\"\" Compute normalized root mse. \"\"\"\n",
    "    return normalized_root_mse(gt, pred)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "755c3b23",
   "metadata": {},
   "source": [
    "All the code from here on is almost the same as before, only for the 8fold data. The main difference is the learning rate, which is 3 times higher for the 8fold data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "44d5dbbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finish data loading- now train\n"
     ]
    }
   ],
   "source": [
    "\n",
    "    \n",
    "data_path_train = 'data/train'\n",
    "data_path_val = 'data/val'\n",
    "data_list = load_data_path(data_path_train, data_path_val)\n",
    "    \n",
    "\n",
    "num_workers = 12 # data loading is faster using a bigger number for num_workers. 0 means using one cpu to load data\n",
    "    \n",
    "#mae_loss = nn.L1Loss().to('cuda:0')\n",
    "mae_loss = nn.L1Loss()\n",
    "lr = 3e-3\n",
    "    #acc =8 , network_8fold\n",
    "network_8fold = ResNet(baseBlock,[2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2])\n",
    "#network_8fold.to('cuda:0') #move the model on the GPU\n",
    "\n",
    "    \n",
    "optimizer2 = optim.Adam(network_8fold.parameters(), lr=lr)\n",
    "\n",
    " \n",
    "train_dataset = MRIDataset(data_list['train'])\n",
    "val_dataset = MRIDataset(data_list['val'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, shuffle=True, batch_size=64, num_workers=num_workers) \n",
    "print(\"finish data loading- now train\")\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "061c8b1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer6): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer7): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer8): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "network_8fold"
   ]
  },
  {
   "cell_type": "raw",
   "id": "69044fe6",
   "metadata": {},
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "then = time.time() #Time before the operations start\n",
    "\n",
    "#DO YOUR OPERATIONS HERE\n",
    "\n",
    "\n",
    "for epoch in range(3):\n",
    "    for iteration, sample in enumerate(train_loader):\n",
    "        img_nr += 1\n",
    "        img_gt, img_und = sample\n",
    "        #print(img_und.shape)\n",
    "\n",
    "now = time.time() #Time after it finished\n",
    "\n",
    "print(\"It took: \", now-then, \" seconds\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8672c18a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:  0.7909698486328125\n",
      "Loss value:  7.620410919189453\n",
      "Loss value:  1.8947722911834717\n",
      "Loss value:  1.4077249765396118\n",
      "Loss value:  0.8669231534004211\n",
      "Loss value:  0.5356665849685669\n",
      "Loss value:  0.23624354600906372\n",
      "Loss value:  0.5122002959251404\n",
      "Loss value:  0.533007025718689\n",
      "Loss value:  0.41509392857551575\n",
      "Loss value:  0.24178458750247955\n",
      "Loss value:  0.3857073187828064\n",
      "Loss value:  0.34383857250213623\n",
      "Loss value:  0.328438937664032\n",
      "Loss value:  0.1806040108203888\n",
      "Loss value:  0.17907381057739258\n",
      "Loss value:  0.36001643538475037\n",
      "Loss value:  0.39473819732666016\n",
      "Loss value:  0.31164953112602234\n",
      "Loss value:  0.2913835942745209\n",
      "L1 Loss score:  0.89151   Image number:  20   Epoch:  1\n",
      "Loss value:  0.15944094955921173\n",
      "Loss value:  0.21021687984466553\n",
      "Loss value:  0.24680185317993164\n",
      "Loss value:  0.16357657313346863\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:  0.09672964364290237\n",
      "Loss value:  0.1351591795682907\n",
      "Loss value:  0.14007502794265747\n",
      "Loss value:  0.13092313706874847\n",
      "Loss value:  0.050123218446969986\n",
      "Loss value:  0.18498435616493225\n",
      "Loss value:  0.2067517191171646\n",
      "Loss value:  0.13607889413833618\n",
      "Loss value:  0.14579762518405914\n",
      "Loss value:  0.11218365281820297\n",
      "Loss value:  0.11840295791625977\n",
      "Loss value:  0.24433249235153198\n",
      "Loss value:  0.1920366734266281\n",
      "Loss value:  0.08282037824392319\n",
      "Loss value:  0.15728087723255157\n",
      "Loss value:  0.12567038834095\n",
      "L1 Loss score:  0.15197   Image number:  40   Epoch:  2\n",
      "Loss value:  0.11813496798276901\n",
      "Loss value:  0.04356745257973671\n",
      "Loss value:  0.10617754608392715\n",
      "Loss value:  0.14789924025535583\n",
      "Loss value:  0.12398886680603027\n",
      "Loss value:  0.0704672634601593\n",
      "Loss value:  0.09117129445075989\n",
      "Loss value:  0.14176732301712036\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:  0.1403551995754242\n",
      "Loss value:  0.06391435861587524\n",
      "Loss value:  0.07524984329938889\n",
      "Loss value:  0.11934733390808105\n",
      "Loss value:  0.09180615842342377\n",
      "Loss value:  0.05721653252840042\n",
      "Loss value:  0.08542433381080627\n",
      "Loss value:  0.10724472254514694\n",
      "Loss value:  0.08774213492870331\n",
      "Loss value:  0.056363269686698914\n",
      "Loss value:  0.063319630920887\n",
      "Loss value:  0.06844070553779602\n",
      "L1 Loss score:  0.09298   Image number:  60   Epoch:  3\n",
      "Loss value:  0.06470206379890442\n",
      "Loss value:  0.030152175575494766\n",
      "Loss value:  0.05604586750268936\n",
      "Loss value:  0.08699667453765869\n",
      "Loss value:  0.061371833086013794\n",
      "Loss value:  0.016511913388967514\n",
      "Loss value:  0.06449716538190842\n",
      "Loss value:  0.06272722780704498\n",
      "Loss value:  0.0314900279045105\n",
      "Loss value:  0.04435262456536293\n",
      "Loss value:  0.057881761342287064\n",
      "Loss value:  0.04599142447113991\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:  0.018626175820827484\n",
      "Loss value:  0.04132964462041855\n",
      "Loss value:  0.03326720744371414\n",
      "Loss value:  0.019041117280721664\n",
      "Loss value:  0.018183071166276932\n",
      "Loss value:  0.024241697043180466\n",
      "Loss value:  0.017157454043626785\n",
      "Loss value:  0.03365086391568184\n",
      "L1 Loss score:  0.04141   Image number:  80   Epoch:  4\n",
      "Loss value:  0.03173430263996124\n",
      "Loss value:  0.016267819330096245\n",
      "Loss value:  0.0202835313975811\n",
      "Loss value:  0.02436235174536705\n",
      "Loss value:  0.021101759746670723\n",
      "Loss value:  0.022445200011134148\n",
      "Loss value:  0.023292377591133118\n",
      "Loss value:  0.018105003982782364\n",
      "Loss value:  0.02180696651339531\n",
      "Loss value:  0.036937110126018524\n",
      "Loss value:  0.05253296718001366\n",
      "Loss value:  0.017686331644654274\n",
      "Loss value:  0.051392387598752975\n",
      "Loss value:  0.05988382548093796\n",
      "Loss value:  0.039204467087984085\n",
      "Loss value:  0.024566682055592537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:  0.020899148657917976\n",
      "Loss value:  0.035548485815525055\n",
      "Loss value:  0.036382801830768585\n",
      "Loss value:  0.036594439297914505\n",
      "L1 Loss score:  0.03055   Image number:  100   Epoch:  5\n",
      "Loss value:  0.015040897764265537\n",
      "Loss value:  0.046638619154691696\n",
      "Loss value:  0.03713975474238396\n",
      "Loss value:  0.021817918866872787\n",
      "Loss value:  0.04122701287269592\n",
      "Loss value:  0.034398335963487625\n",
      "Loss value:  0.03327992558479309\n",
      "Loss value:  0.04439117759466171\n",
      "Loss value:  0.03834383189678192\n",
      "Loss value:  0.01327536441385746\n",
      "Loss value:  0.04233503341674805\n",
      "Loss value:  0.047970958054065704\n",
      "Loss value:  0.030778875574469566\n",
      "Loss value:  0.025704598054289818\n",
      "Loss value:  0.03967954218387604\n",
      "Loss value:  0.042257413268089294\n",
      "Loss value:  0.03351745009422302\n",
      "Loss value:  0.03546319901943207\n",
      "Loss value:  0.03188879042863846\n",
      "Loss value:  0.01841234415769577\n",
      "L1 Loss score:  0.03368   Image number:  120   Epoch:  5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss value:  0.03165518119931221\n",
      "Loss value:  0.03177431970834732\n",
      "Loss value:  0.020259175449609756\n",
      "Loss value:  0.03438343480229378\n",
      "Loss value:  0.03823702037334442\n",
      "Loss value:  0.01576167345046997\n",
      "Loss value:  0.03373564034700394\n",
      "Loss value:  0.048366978764534\n",
      "Loss value:  0.031086206436157227\n",
      "Loss value:  0.021101756021380424\n",
      "Loss value:  0.03821727633476257\n",
      "Loss value:  0.0249024648219347\n",
      "Loss value:  0.014956620521843433\n",
      "Loss value:  0.0327637605369091\n",
      "Loss value:  0.024318834766745567\n",
      "Loss value:  0.01569484733045101\n",
      "Loss value:  0.02003948576748371\n",
      "Loss value:  0.019192952662706375\n",
      "Loss value:  0.016234561800956726\n",
      "Loss value:  0.026415014639496803\n",
      "L1 Loss score:  0.02695   Image number:  140   Epoch:  6\n",
      "Loss value:  0.017312994226813316\n",
      "Loss value:  0.01941266842186451\n",
      "Loss value:  0.02638186328113079\n",
      "Loss value:  0.01093438733369112\n",
      "It took:  29976.431304216385  seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import random\n",
    "\n",
    "then = time.time() #Time before the operations start\n",
    "losses2=[]\n",
    "mean_loss_list = []\n",
    "img_nr = 0\n",
    "epoch_nums = 6 #64 # 5\n",
    "for epoch in range(epoch_nums):\n",
    "    for iteration, sample in enumerate(train_loader):\n",
    "        img_nr += 1\n",
    "        img_gt, img_und = sample\n",
    "        \n",
    "        img_gt = img_gt.unsqueeze(1)#.to('cuda:0') # img_gt = img_gt.unsqueeze(1).to('cuda:0')\n",
    "        img_und = img_und.unsqueeze(1)#.to('cuda:0') #img_und = img_und.unsqueeze(1).to('cuda:0')\n",
    "       # img_gt = img_gt.to('cuda:0')\n",
    "       # img_und = img_und.to('cuda:0')\n",
    "            \n",
    "        output = network_8fold(img_und)      #feedforward\n",
    "        #print(output.shape) #// debug\n",
    "        loss = mae_loss(output, img_gt)\n",
    "\n",
    "        optimizer2.zero_grad()       #set current gradients to 0\n",
    "        loss.backward()      #backpropagate\n",
    "        optimizer2.step()     #update the weights\n",
    "        mean_loss_list.append(loss.item())\n",
    "        print(\"Loss value: \", loss.item())\n",
    "            #compute and print the mean L1 lossscore for the last 20 training images.\n",
    "        if img_nr%20 == 0:\n",
    "            print(\"L1 Loss score: \", np.round(np.mean(mean_loss_list), decimals = 5), \"  Image number: \", img_nr, \"  Epoch: \", epoch+1)\n",
    "            mean_loss_list = []\n",
    "        losses2.append(loss.item() * img_gt.size(0))\n",
    "        \n",
    "now = time.time() #Time after it finished\n",
    "\n",
    "print(\"It took: \", now-then, \" seconds\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2f0d027e",
   "metadata": {},
   "source": [
    "From the Pytorch documentation on convolutional layers, Conv2d layers expect input with the shape\n",
    "\n",
    "(n_samples, channels, height, width) # e.g., (1000, 1, 224, 224)\n",
    "Passing grayscale images in their usual format (224, 224) won't work.\n",
    "\n",
    "To get the right shape, you will need to add a channel dimension. You can do it as follows:\n",
    "\n",
    "x = np.expand_dims(x, 1)      # if numpy array\n",
    "tensor = tensor.unsqueeze(1)  # if torch tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7da32f5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f59efc7b-fde5-47a8-a566-f5ca13563301",
   "metadata": {},
   "source": [
    "np.moveaxis(arr, 1, -3)\n",
    "https://github.com/scikit-image/scikit-image/issues/4636\n",
    "https://stackoverflow.com/questions/68079012/valueerror-win-size-exceeds-image-extent-if-the-input-is-a-multichannel-color"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7795a478",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:21: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/skimage/metrics/_structural_similarity.py:208: RuntimeWarning: invalid value encountered in true_divide\n",
      "  S = (A1 * A2) / D\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/skimage/metrics/simple_metrics.py:105: RuntimeWarning: divide by zero encountered in double_scalars\n",
      "  return np.sqrt(mean_squared_error(image_true, image_test)) / denom\n",
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/skimage/metrics/simple_metrics.py:105: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  return np.sqrt(mean_squared_error(image_true, image_test)) / denom\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.688459476229256\n",
      "0.007103989595072739\n",
      "0.11877264670949504\n",
      "0.1203626824700856\n",
      "24.05844166101943\n",
      "inf\n"
     ]
    }
   ],
   "source": [
    "#compute the SSIM score for every image after a feedforward propagation through \n",
    "#the network.\n",
    "#Subtract the image SSIM score before the feedforward prop to obtain the net improvement for every image.\n",
    "#Print the average improvement and the average SSIM score after the reconstruction.\n",
    "SSIM_improvement = []\n",
    "SSIM_score = []\n",
    "MSE_improvement = []\n",
    "MSE_score = []\n",
    "NRMSE_improvement = []\n",
    "NRMSE_score = []\n",
    "for i in range(0,len(val_dataset)):\n",
    "    gt, image = val_dataset[i]\n",
    "    #image = image.unsqueeze(0).to('cuda:0')\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.unsqueeze(0)\n",
    "    gt = gt.unsqueeze(0).numpy()\n",
    "    output = network_8fold(image)\n",
    "  #  output = output.squeeze(1).cpu().detach().numpy()\n",
    "    output = output.squeeze(1).detach().numpy()\n",
    "    image = image.squeeze(1).numpy()\n",
    "    gt =  np.squeeze(gt)\n",
    "    output =  np.squeeze(output)\n",
    "    image =  np.squeeze(image)\n",
    "\n",
    "\n",
    "    output_loss1 = torch.tensor(ssim(gt, output))\n",
    "    output_loss2 = torch.tensor(mse(gt, output))\n",
    "    output_loss3 = torch.tensor(nrmse(gt, output))\n",
    "  #  image_loss = torch.tensor(ssim(gt, image.squeeze(1).cpu().numpy()))\n",
    "    image_loss1 = torch.tensor(ssim(gt, image))\n",
    "    image_loss2 = torch.tensor(mse(gt, image))\n",
    "    image_loss3 = torch.tensor(nrmse(gt, image))\n",
    "    SSIM_improvement.append(output_loss1.item()-image_loss1.item())\n",
    "    SSIM_score.append(output_loss1.item())\n",
    "    MSE_improvement.append(output_loss2.item()-image_loss2.item())\n",
    "    MSE_score.append(output_loss2.item())\n",
    "    NRMSE_improvement.append(output_loss3.item()-image_loss3.item())\n",
    "    NRMSE_score.append(output_loss3.item())\n",
    "\n",
    "print(np.nanmean(SSIM_improvement))\n",
    "print(np.nanmean(SSIM_score))\n",
    "print(np.nanmean(MSE_improvement))\n",
    "print(np.nanmean(MSE_score))\n",
    "print(np.nanmean(NRMSE_improvement))\n",
    "print(np.nanmean(NRMSE_score))"
   ]
  },
  {
   "cell_type": "raw",
   "id": "9ba92d80-ff2a-4cc7-a0d1-ba55184f0938",
   "metadata": {},
   "source": [
    "#compute the SSIM score for every image after a feedforward propagation through \n",
    "#the network.\n",
    "#Subtract the image SSIM score before the feedforward prop to obtain the net improvement for every image.\n",
    "#Print the average improvement and the average SSIM score after the reconstruction.\n",
    "SSIM_improvement = []\n",
    "SSIM_score = []\n",
    "MSE_improvement = []\n",
    "MSE_score = []\n",
    "NRMSE_improvement = []\n",
    "NRMSE_score = []\n",
    "for i in range(0,len(val_dataset)):\n",
    "    gt, image = val_dataset[i]\n",
    "    #image = image.unsqueeze(0).to('cuda:0')\n",
    "    image = image.unsqueeze(0)\n",
    "    image = image.unsqueeze(0)\n",
    "    gt = gt.unsqueeze(0).numpy()\n",
    "    output = network_8fold(image)\n",
    "  #  output = output.squeeze(1).cpu().detach().numpy()\n",
    "    output = output.squeeze(1).detach().numpy()\n",
    "    image = image.squeeze(1).numpy()\n",
    "    gt =  np.squeeze(gt)\n",
    "    output =  np.squeeze(output)\n",
    "    image =  np.squeeze(image)\n",
    "\n",
    "\n",
    "    output_loss1 = torch.tensor(ssim(gt, output))\n",
    "    output_loss2 = torch.tensor(mse(gt, output))\n",
    "    output_loss3 = torch.tensor(nrmse(gt, output))\n",
    "  #  image_loss = torch.tensor(ssim(gt, image.squeeze(1).cpu().numpy()))\n",
    "    image_loss1 = torch.tensor(ssim(gt, image))\n",
    "    image_loss2 = torch.tensor(mse(gt, image))\n",
    "    image_loss3 = torch.tensor(nrmse(gt, image))\n",
    "    SSIM_improvement.append(output_loss1.item()-image_loss1.item())\n",
    "    SSIM_score.append(output_loss1.item())\n",
    "    MSE_improvement.append(output_loss2.item()-image_loss2.item())\n",
    "    MSE_score.append(output_loss2.item())\n",
    "    NRMSE_improvement.append(output_loss3.item()-image_loss3.item())\n",
    "    NRMSE_score.append(output_loss3.item())\n",
    "\n",
    "print(np.nanmean(SSIM_improvement))\n",
    "print(np.nanmean(SSIM_score))\n",
    "print(np.nanmean(MSE_improvement))\n",
    "print(np.nanmean(MSE_score))\n",
    "print(np.nanmean(NRMSE_improvement))\n",
    "print(np.nanmean(NRMSE_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b2c6aeb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc627f4e510>]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SSIM_improvement.sort()\n",
    "plt.plot(SSIM_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82dbcb1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc627ecae10>]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MSE_improvement.sort()\n",
    "plt.plot(MSE_improvement)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb47ebd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc628132990>]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "NRMSE_improvement.sort()\n",
    "plt.plot(NRMSE_improvement)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23428529",
   "metadata": {},
   "source": [
    "## save Model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "eb1c0afb",
   "metadata": {},
   "source": [
    "https://learn-pytorch.oneoffcoder.com/model-persistence.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7ed9882d",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "afffbf01",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = f\"s3://savemodels/network_8fold/restnet-model{index}.pt\"\n",
    "output_dir = f\"./network_8fold/restnet-model{index}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "47fcce68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#save model to S3 bucket or data\n",
    "torch.save(network_8fold.state_dict(), output_dir)\n",
    "#torch.save(network_8fold.state_dict(), './models/resnet18-model.pt')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "de009c4f",
   "metadata": {},
   "source": [
    "#save the whole model\n",
    "torch.save(network_8fold, output_dir)\n",
    "#torch.save(network_8fold, './models/resnet18-model.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc56219",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Load Model from saved model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9718f388-6792-42eb-9ede-ad730317cb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "23b955f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#output_dir = f\"s3://savemodels/network_8fold/restnet-model{index}.pt\"\n",
    "output_dir = f\"./network_8fold/restnet-model{index}.pt\""
   ]
  },
  {
   "cell_type": "raw",
   "id": "e9d7ffc6-c8a7-430e-a4ad-313287b60833",
   "metadata": {},
   "source": [
    "#load model on GPU\n",
    "device = torch.device(\"cuda\")\n",
    "model = ResNet(baseBlock,[2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2])\n",
    "\n",
    "#model = model.to('cuda:0')\n",
    "model.load_state_dict(torch.load(output_dir, map_location='cuda:0'))\n",
    "#model.load_state_dict(torch.load('./models/resnet18-model.pt', map_location='cuda:0'))\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5448b9e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "67996389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer6): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer7): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer8): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model on CPU: laptop\n",
    "device = torch.device('cpu')\n",
    "#model = TheModelClass(*args, **kwargs)\n",
    "model = ResNet(baseBlock,[2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2])\n",
    "#model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model.load_state_dict(torch.load(output_dir, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d0fb806c",
   "metadata": {},
   "source": [
    "model = torch.load(PATH)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170c0fb0",
   "metadata": {},
   "source": [
    "## Predict a single image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "74ad0dc8-645b-4c17-b2b1-4029244808a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "index = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0aa3f9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model_dir = f\"s3://savemodels/network_8fold/restnet-model{index}.pt\"\n",
    "model_dir = f\"./network_8fold/restnet-model{index}.pt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ad022822",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ResNet(\n",
       "  (conv1): Conv2d(1, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "  (layer1): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer2): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer3): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer4): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer5): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer6): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer7): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (layer8): Sequential(\n",
       "    (0): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "    (1): baseBlock(\n",
       "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    )\n",
       "  )\n",
       "  (conv2): Conv2d(64, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#load model on CPU: laptop\n",
    "device = torch.device('cpu')\n",
    "#model = TheModelClass(*args, **kwargs)\n",
    "model = ResNet(baseBlock,[2, 2, 2, 2, 3, 3, 3, 3, 2, 2, 2, 2])\n",
    "#model.load_state_dict(torch.load(PATH, map_location=device))\n",
    "model.load_state_dict(torch.load(model_dir, map_location=device))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "214e7b82-ec39-4884-b875-c23f067c170d",
   "metadata": {},
   "source": [
    "https://www.cns.nyu.edu/~lcv/ssim/\n",
    "\n",
    "-0.08275149106735159\n",
    "0.4152959283673115\n",
    "-0.0008673634965751041\n",
    "0.0009822993672129392\n",
    "-2.285560072865337\n",
    "inf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16d3b135-723d-435d-bb9c-ae79c2321953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cec45d6-77fd-4e9b-bce1-6e1509314857",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f1e7bc-59cb-4f2c-ad59-98f414e8154c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85e662-842f-4cc4-8843-1a15346d481b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c4b75fd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "240b151f",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_dir = \"data/test/images/244.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ff493574",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:16: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  app.launch_new_instance()\n"
     ]
    }
   ],
   "source": [
    "im_frame = Image.open(file_dir)\n",
    "   \n",
    "noise_im_frame = noise_and_kspace(im_frame)\n",
    "\n",
    "preprocess = T.Compose([\n",
    "                       # T.Grayscale(num_output_channels=1),\n",
    "                           T.Resize(128),    #128 as maximum\n",
    "                           T.CenterCrop(128),\n",
    "                           T.ToTensor() #,\n",
    "                           #T.Normalize(\n",
    "                            #        mean=[0.485, 0.456, 0.406],\n",
    "                               #        std=[0.229, 0.224, 0.225]\n",
    "                             ##         )\n",
    "                            ])\n",
    "img_gt = preprocess(Image.fromarray(np.uint8(im_frame)).convert('L'))\n",
    "img_und = preprocess(Image.fromarray(np.uint8(noise_im_frame)).convert('L'))\n",
    "    \n",
    "n1 = (img_und**2).sum(dim=-1).sqrt()\n",
    "norm = n1.max() \n",
    "if norm < 1e-6: norm = 1e-6\n",
    "    \n",
    "img_gt, img_und = img_gt/norm , img_und/norm  \n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8ae03d59-a632-4194-971b-b17417c24dee",
   "metadata": {},
   "source": [
    "torchvision.transforms.ConvertImageDtype\n",
    "torchvision.transforms.ToPILImage\n",
    "torchvision.transforms.PILToTensor"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8c636e0f-46e8-4054-b137-de326985c275",
   "metadata": {},
   "source": [
    "im_1 = img_gt * norm\n",
    "#im_1 = im_1.numpy()\n",
    "im_1 = T.ToPILImage()(im_1)\n",
    "im_1.size"
   ]
  },
  {
   "cell_type": "raw",
   "id": "62042616-a908-441a-b0a7-d56a73416501",
   "metadata": {},
   "source": [
    "display(im_frame)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "58edadac-1acb-4d05-b102-cb4dfcc9c7c3",
   "metadata": {},
   "source": [
    "display(im_1) # success in turning Image into right input"
   ]
  },
  {
   "cell_type": "raw",
   "id": "21476dc7-a09b-4997-842d-7fe3ed9228e6",
   "metadata": {},
   "source": [
    "np_image1 = np.reshape(im_1, (64, 64))# image noise numpy array\n",
    "im_r1 = Image.fromarray(np_image1).convert('RGB')\n",
    "display(im_r1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "106789d1-862f-4ee8-925a-c51452b936f4",
   "metadata": {},
   "source": [
    "im_frame = Image.open(file_dir)\n",
    "   \n",
    "noise_im_frame = noise_and_kspace(im_frame)\n",
    "\n",
    "preprocess = T.Compose([\n",
    "                       # T.Grayscale(num_output_channels=1),\n",
    "                           T.Resize(64),    #128 as maximum\n",
    "                           T.CenterCrop(64),\n",
    "                           T.ToTensor() #,\n",
    "                           #T.Normalize(\n",
    "                            #        mean=[0.485, 0.456, 0.406],\n",
    "                               #        std=[0.229, 0.224, 0.225]\n",
    "                             ##         )\n",
    "                            ])\n",
    "img_gt = preprocess(Image.fromarray(np.uint8(im_frame)).convert('L'))\n",
    "im_1 = img_gt.numpy()\n",
    "im_1.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "885c0d8b-9500-41c6-bf8f-3206eabfd132",
   "metadata": {},
   "source": [
    "np_image1 = np.reshape(im_1, (64, 64))# image noise numpy array\n",
    "im_r1 = Image.fromarray(np_image1).convert('L')\n",
    "display(im_r1)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "3ed528d5-9046-4abd-b107-0436cdd6b576",
   "metadata": {},
   "source": [
    "image = Image.open(file_dir)    \n",
    "img_fft = fftshift(fftn(image))\n",
    "np_image = np.uint8(img_fft)# image noise numpy array\n",
    "im_n = Image.fromarray(np_image).convert('L')\n",
    "display(im_n)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "f705ae9e",
   "metadata": {},
   "source": [
    "https://www.kite.com/python/examples/4887/PIL-convert-between-a-pil-%60image%60-and-a-numpy-%60array%60\n",
    "\n",
    "https://stackoverflow.com/questions/2659312/how-do-i-convert-a-numpy-array-to-and-display-an-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73094677-ada9-48d4-94dd-70bb1bb0bbf8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "31688b6f-03c3-4cd3-8754-0ec5095a07f2",
   "metadata": {},
   "source": [
    "from IPython.display import display\n",
    "display(im_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "fc9a3f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.metrics import structural_similarity as cmp_ssim \n",
    "def ssim(gt, pred):\n",
    "    \"\"\" Compute Structural Similarity Index Metric (SSIM). \"\"\"\n",
    "    return cmp_ssim(\n",
    "        gt, pred, multichannel=True, data_range=gt.max()\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c7bafb7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "    #noise_image = noise_image.to('cuda:0')\n",
    "#img_gt = img_gt.numpy()\n",
    "img_und = img_und.unsqueeze(0)\n",
    "output = model(img_und)\n",
    "   # output = output.squeeze(1).cpu().detach().numpy()\n",
    "output = output.squeeze(1).detach() #.numpy()   #image under numpy form\n",
    "#output_loss = torch.tensor(ssim(img_gt, output))  \n",
    "#image_loss = torch.tensor(ssim(img_gt, img_noise.squeeze(1).numpy()))\n",
    "#SSIM_improvement = (output_loss.item()-image_loss.item())\n",
    "#SSIM_score = output_loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "652b07c7-95ac-47bb-a8f7-bbc59d10d02b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 128, 128])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a0404e71",
   "metadata": {},
   "outputs": [],
   "source": [
    "np_rescontruct_image =  output # np.reshape(output, (64, 64))# image noise numpy array\n",
    "im_reconstruct = T.ToPILImage()(np_rescontruct_image)#Image.fromarray(np_rescontruct_image).convert('L')\n",
    "im_reconstruct.save(\"testing/test.png\") #for prediction values\n",
    "im_reconstruct.save(\"pred1.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "2c66ce9e-8dcc-47b5-9d26-8461dc6cefba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FC628F0F0D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(im_reconstruct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b22263aa-0947-4689-b648-8edb9e9560f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAA2UlEQVR4nO3XQRKCMBBE0dED5zCe2CWFEexkeooK/rdSF/KrQdQIAAAAAAAAAABwsYfpfVpEvC4LaNvD4QhDQNs/HUzIB7TulaGEZzqg1yedSC/w/Wj6CBULxMgI2YCjI8kFRQvoBWUBakFdgKgwQJugcgGp4M6nQJtg+QXO77nCBMsvcH1A9hysv8DcT1FnQJIhIDfBHRbITWBZIFPgOQWJAtM1MF/guggPCn6H2T4Fsxu4/p5HTP5LdN4HusMpqzgXiI8RpLNiDtgakt9RAAAAAAAAAAD8kTfBnhRjvwDDbgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=128x128 at 0x7FC627F858D0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(im_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0828b370-d8fc-4097-bf1b-75f1d0e3ab52",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:1: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAIAAAACACAAAAADmVT4XAAAY60lEQVR4nE2bW5IlSZJbD6B2o5pbJZvTw42Q82h+cKUzlddVwQ81z56qkhLJjIgb7qYvKABDGpQOTowCPzBPPDIohiFKoML+E4BkhkAgA5T2ixZYzHiEChqGAjwglMaDAyRBpGVoghBDLKwhDyAw8oyHSMQQDQADMNIc5CGDDgwOGTAInhqB3SEIiG0y2Q8fGIkhk3/8lcgUiKKHNknjCMggUBAKNCBCVYUS6D5dowzaF4gEQ58EZSIolHTJwCEdwn1xEtDgPf2JqA54jzoVMpMSymSPoUUaa2OjGwxkCVEY2SDfAMp0uN+XEe/Xk2w8m3k80BNv5I2CXEGDmCh94y/vB+zfKFKrxITII1cJIdyKmGcfIxRoIx6QRODcpNo/SiCBJ+rpfT+TMLxvCTICukIYhoY5e1wGzR6JIlQ4WKAnk5gA0hnbzNlD2E+Fn859qGSKyBvTwOOTINggwshE9wdm0EA/8cC5ubVB1I2DPsTj+7dEZiZFRXO6ncpm155xoLtGAJogzaRqoHtSYeTsR28MSZlKRi59xw701HTRiGgTwBQRaIQnuHn2FScTPyB6s5Kn+AChtw+cm39hI6kxGYlUA3iKMWqhmTiMUKsGwkmGsTFUCMnMnp+Z2POWYwrlhLDxwjJVIJegwiQMPAhv7/CUzNinNQWJKFFwe9dAHrJdTBgMdAb8GPxAZIz9doYUvU+ngAJCFpANSoP1HDnRJEj+MjWJQIwIVO35BdTaMswANmHTid66hpxzQ8VU4lGofXwSwZkT3wyTZ8AWGwDNzH5lHMg4COZLJEk+9IRptMWS/e4AbsfzbbJJJwskGSZAeMBx4j0Mg8oSdA9jmknHZkagHxDeNwlsN0R+R4s3PBnJtJLNDSMlo7wtd7N3U1IFcQlBgfZccHQfe6JWhJVSqsD1zjAMmtHZkr/9MGHr6XmyH2NrbgMZ0olui8j0lm6hUTQ6UjIcBp63bm5LcWn6vmvIuPa1H71NYBNhasBOGu5gjnS2G8whHEekdYtvkBTl7e/vFAgidTuWpC7erIItSs6NJt4fCCpuCyzXzH7+iGhbaniEGCnDFpbYPr1ZLkklAdEWLW6aiSOHunBC0JkE20ERbc0d7Wlur+Ohgqyg8g7m34eIeivT92RTjBjE2UP1U1DkHgxmmEc1M8QpLh7YWB2OFW6A4yi5zaLjCSY17IgHpufJKXmxxEU5NKXfNU7gs28zghArfHizUMmOPwU5GuoEnu12253UZGLUyEF5vLFOiC7+yhaQAFU2qZCyY5BtpDxPgTHwJQ+1hV3Mrf5uuphEH/SAqOhGpkD6fWKMUpastyahQyVkRskx0ky/HewODCfKLVASPRomxewRaTKQvlFAvahM0Whbj4GKgpFMnnn0TstsaURkKpYY6WmGgYi+7XIBIT9o6yVbhMIxdmTCkIqZBvNUNL8TprYtLdas1kgLTJLR7zbliNAFgzYLH6HbyHxyQYVsh6IQ25lamRNmUJRk8hurOlg9Ozfp3nKaxYBTGm8f1UBsQWkutFRlYSXxDr4Zh8/WUbj/r9ALdtMN1O0oC/G3IaJGR2zB5+0+im+fJziL/p4b/lASfuuET37/HF5sT8nE/GPSJBEstAPII/IECvrMDs2pHlMBhxdmxV9zIM2MJrPdPXob14KxJzutYe6jZ4FI7fMghgOf0Fv+vBNIpUXTepejjhnjXsx546s0pgfDNNkznBGKDKnZuG/7GoYQReBfFUxU8kUrM4uLs8WcqEY0yQnAMEgRcxiowu8XFlXd543UOLHUdzHh/R2pmdBA1PRoUXeH0JFMkSHJmFk4jHJgLOinaoiJstlh3WRrC0Y6M6jRu41M82KQ2NHji7JtMmoijRNNKY4X89xYaLtX1Q2Eh9DeRFpwmML+voMgjJjyqfM8wqafO3UchsMjHs1A0PH2i7o4yreZkXhaGv2eMXQuNn5mVzC0c3c7Zb/BkUJt3hnneYJxiBDe/S2DtvTFJEI6+T1YgHPM2OaB3jaeha3sHnI32804hSHBJ8MUD2OjYN/V8y6GzzaNO7YmoCf4O7KT+6XKXbLwwmQbTer2qdmmO3iRoyp0eIgpvxNHmS3lzboNaAG4wdkkrLsa5NanXDLS3G2c7OZQ42yXGimL7EMYi3Yhaf+8tIUMOjMzYFwpPb8XNjxSGeMTosUe2Q+fuY1rc88PFEn8dpV4czSUrVneYDFgondn8LSZUNQ+pJn6nUlvlDVDpDgUcUjObCQXBThsmzTazh46O9m5w/kebcOYhWfg2Jtk/gI9yd2udRMc9XI2srt+7whn2IyiP0yBtaunLkxATBrabw5NcegeV+sB3CW/a3jZ0NxZMYzSA/9YkIS2jCkIchnSz40hjeArkrx9NGaPZiP1oNxTPi+Xg6Op7kS2xj3BpvP9zRQVI5gCXFvmvUAoSC92bxVTdVvL/rew1IRS0ixi4N20XNt2yMBovD3MuVtlTCMcfCRav8t+3tjAQ8b13JxCJhzU0rxQWSrDgN0O4ggyZNR3FVM+s9MmcHbFfDPhkIPQgUukIcKyFb+TVHBjHeLcJ6zkbJ4Ez+1KIQmU5X+AikDFvhzAnhLm7qgNhtIitSe++LH0DliDiBfk8YQujYUXBu8Q3l1mGCctxkShpTMUuC3Si6GDnkRjyFfPZZGC1Lu4Cs3ied6TuIsD6TAC7FbmqN5YmTCZt9rv2CL3UcjgZ1OX5x+fWQTNVMEnIpRqU2AbrxpZUb/9G1EptEN1W23GClgdX3Bz8asqFs+2M9l6CGjKHSIGOi5GL3JmFiW+CKddG0ch5SANfetgV+7Zkal3vXpnkl1QniUFvSxZFDKhyngxAi+JWcwQtyQ9vumi8fOe57b9JBJ1LjOqpmZntC4jvXsx0eJLiWSYWO6g0Zjj5UaUko6Kl6JBZKaSDKXlMaTtr/e3RNQzn7N80QE0GiUpXwo0Gka4dloWkBwNnH3Qu8iVbteWG49oKVAtN3LaWUxBSKWpKNWejfCfP545LfzfXf/x/xIPNaP+DBGqRumT5zBG508hGHFa6vOr6qttSKk4z2kFLbRb6FN8TwA3hjxViR+TCs+yEFP627QOjyrzr4rG7V0jaqsRrN5FYExi6W10kTQkVU90eJQ4U9nvVuQGnlIUkhoJjUfj053Ck7+hjPvzxPUt/58uVUOmooj+ZMf8uM9IQz4d1FrGFFKT+laE1FIQbs6jHTqb2v3JnMehvpx+sQRd/POTmg+Pppz2c57/K5hwsmTDsgpGjxxnvB9rHmnhTdAUVZMcRjz5xr8U6i+MYaL6aNwz8EUjDbMTK06ZPM1IHc+Z87dM6jjTux3tOl+pxRU7QqbnI8ViTu4ZLS8vzRIMsebFFR7oWp46en52NM/Rn//LiZkpJedPyfFQ/5JKMPpWW9xQHn2DRpK/P4/154nOggR5Io2RNCyJ+uHB5wKX3ElmS3E9mmrU8sznz+NUej6PPzNWPfM3eXnfRGTOuBUeWHgyOsPwweMu5iw/NTXpHgYewxeV5p1EquUVpGWHjErmn37UR183n4oyPaPHo7/NcqZCxl9/6RkqHRmsnmU97DyUFl65pY9xaV5WH9E8RUq/xLjoZ3fS7nlKKKJUMtGI2cfT5H+61X38GDjzQT7uI5mkpSMe0XYddWLR2yV3ocFcspKKHZrjsjoNx8wciW7yVH7hrz+W55CfBbTw18g1nEyS/ELM0FaWOV/0kDG/5qy00jY9MBGfHUx8jcxjEAsgfaohJaiKpOan88nTHR77qxlbrXOeC+YkSSp21Rqkk2hmvnNsfe5MmAO4RnUQg5pf1DBPFPQMQxx6Iv5bRpl2cpRW4jz2cVNd+ZKf+f7NDPI0TxhWjZlvoZlUxLH4ep6lk0TfLV7P0CHWj4w4erCqYvXClvajiaCpb0BR+EvpOcXjX2KS2P/0lDzyHFTTOTMVD9JoUEOoZbXGPDwISYmLqV1IJvkMB56drW07OMGrZfGRU0rr16BfGfHRpz3kS6UGyUyk4+9x/+An2cNuO4/VSavnqNAkUDN4zAIJ/nRPX3jqmj4WUzuqTvo/c2o8is4z1VIXOlNE+idk7wremSjomyl7MIMmHPdn/APp5YhNmoLzjEUsaopzMQ+t8+3dBwwzcqXJqJJ248h/zvjTZc/A8/29tNHBLty5/M1JxodPJtTdK3uK9DBV44WbkiLXqRh9+xKdy8rzb1XTSkY152fQ5I/JN8rp+K9f8/Qwjxa4NUrI6sVcvSyTiFn47pPIkTIZzyVx3D2Pqpk/RkZPqB2o6Clminr4lRx15UN18p+lx9LR4VWxhfKAJvIKMsGXyxvXNM7MbsjfFt0ySpopwSTRL03iDzzpKzRT+SNPfuCrL+5n17k/uvQ40UjSOGrqQbJ1wW/jXSzKKpoaIj07Ge35mUwj+bumgAj/jKIe7Px0nur//cnXTfnh54iUzgNJvn4++uvlyH0GfpSS9OyJz65cTr0slIcB/SypOfr0Ll/qqiWgUulzkYhp8cf8cZQyz3msZ5imvmdGUjp9EJb0pZ1sB+APlYJsfkisJ6GSnvJdTMkk/vNri0g4XXkUq6dnNX19Tal7fv2Lmf7jS/dxzqEnSSdHuvIv80nGRzT+5huGDKM/hayY6o79C1k9ZFKyXMPcpJ1fqXRaqmpdxqRDm7/QNe609Osw36haP7ETbCZ46CmlM8graaOfYQqVR6j5yJsCH81q5xh8lvr0kWSlsFIkycepUJ6v/z6jnHL9PNEP3WTclTMZnYXZNPaTgb72kGcF+7ZUySLjLJcan7HXyRNJmnQ12e48ig88mqvdPuiP1EzmecqTz/n4KT+a8oej6cZRNKfcU5aTWhlLymFXiGm+i1U11Y6c5DzcRXiKp8r4WSdGP8ejpwFHf/Ujt2SeKHpSyMl5xC+U8+BdhrIUKtfsUFOy1daMpHJPnqYaq0v4ubWXWv1ePYqj7lSo+VzB8u+O4pNjfj6JzBekb9kkprpQYUk9j6J8aoaJ85wZz7Exia1BareOl7FEaOSOlLommVjBVCIT0VP/Y1Qt53w59ShempZ5Ko/q9Pp2fnSZiD/NBwPHX8dPM0rs6fVEXcYp3M2t28lq/RTMVHG63FF5kP5uTzO/VoorTUXfB+YzKatrF+n/2F3k+/NxPbE6+LNZV5Yel3imbDyK9qeW13yUYrybiTLf+QbxaJA1+ffGMwd98hBVz/Mzo79niYJ1YeUHjXnOr5kmw5GtdbBNQzHozPeDk8TYv850vngR6sHhg/iojsLUJxpHKP/WOWnPUx9liD5PzRdNnmp9Eml75TyVQuKQoUVqiOZ8q/dlZw7RePT57v5KPf3zqO0uJUzNKpXMpVZaoH/iMRrXINFC/6qn4kUD1KPWLps1URSmYtwU/NFV5QLlFOW4xReE3DzxI0ohkbjWkROctBksyX8XOTHPTM+c4V8nNVlcY7eg0lj1pKem4liL7cZz2rmWAaJ6+lDxA89PRpezyJk2mvlMxHjZ8u95jKdL/0wezenW8fzb5lCvNNCX51B23zyr7N5FBg9yWqmMr8o8mp8VD8cozGfSR+3g8aMVnzVtaUwN5uu/Arj/3bNGsvzlz+secTBJF8lhqEdanm05dvNyqVqu+BULlOkio3pC8OlaCeUSPSLj9XH5rRylQOOcNOMZi7WjJYFTlVsbJivKLQ105iMc6MPrXluhjW27Q8YJjKeXmPXLXwd5RY5lyQSf334dt+Y375sxg/EsSz58X0/FmiyjGpWoZae9MmKNZl/ZO0GcvivsWroQWl1f1ydVZFX2S8B7Nce5DUbAsBz7ATyq5VtrNf8mMAvjyUmE9Vr4NqyCPpfIwcLs0uydSLr2EF//lzGifPehPa0gBbOWxbYGW9T1Qq1W6bPrbrgtQDXXxSjxOOtaXX7ou7rLNQDC5JtM0loYcLxOtIQ5laynNk8iP4BWEBYrUATyiV7ufB2aq8AtfzKpOPRzCd5yavBorrzSubL7ym7MyJejJcxvVgZWtqjff79u0/UWr+x8+VlIcanY9zWXxk3T0mrMq+fm6pqBiXulaWs9mtGO2NUKPmVfTsivMHxWDJeuV1OvTe6sRMsA3uqCwbUi5tLErP565fmrycwgxas59mRpsl2eIj1efZ6G8lqBQC1LKpHJ0uRqMcqtUWWEUULpWjfbNdd46bVJrhI1Ju28jjvntaDF38xqnnmLn9f6ENQCjxWTjVo5Vy9MoDcueZX1A/I1Nww0FV1nVvx6fa4v0tmD9GBd0kIZCD3zrCKq3U1njRloChj6e+1gv63G8XbV0ayw4zWHPNx2k4C7wykI9FKJBV+smHGqdR8WE0/B2SVxvd6+XkLFDw4c2eEq/IdeDKoFGmLLXA9pL+f4lty2KlXsJAElTymCYWr6iil0uO9s6PWd6r+MkrHFZ6Ii3kQ2otZZ91bCCulqR9seNfjOhKupAXWZ/WvKD8rySYtAVpdYtrs2ZQRkp9tKRBpJZ92RV9kyyOL6RUKxbN0lPFKBU9cktGJZAVoVytFw+4vC/ju1LCdP50mV9dxR6Wt1InwKVNd+uGyGBtedYuimuU6dXrN76Rr+V6eelhpp7ajMzuPX9fqy9yLbYT/PdGC9oCDNa9qdZ30M6/1Xg+Z5kMcPZDxWP7sQ3YS1UK77V6MrHUlfLZEWDQtW3y4Z9gxWaEBPso95NuDX6ne1ezG/nuwqzbhRKof17o5mKZOR4213ZlSrNb0qHVf63ra0iuT4d15seaaVbTWQojs56pC6yVG9FQGQx9wTjjA5z5LjXvURzYcedXiM6ddzE90Zrc/oqmNbJma9yPJOpNXu84YvKy6pSeKMKZIi0oSayA8HFOvPzTHKk1BXc+vI72dfs5KBWepvwcD7DQHpoGQWV3I9fKxOJQ2fC2j6um2XIv0s57L+aBbGeQ3rn7l+htenCWQtveGhVsf1m7XJyJsPt4XSY7hm0ZUogMNv3yPNNZwtmoyIz/XgeUeOtzolcLI+Dxl7KQirVoNdRKF/iF+TkPdjAZ3fqWyRcx8h26Iz6z9YK5OyXuMZX3emrumGeKXxC1O3fq6JetHxewD0aK+K6IRJmhet+ALjnJtTvkNiWxhMaG/nzB5OZXpn6mr2eYePWsncawEl1eq+zjVX2lCrmnnWTEvMDOqdJvNCm+BpnhWXJ6NXEgYy1Y9DmWl8c6u/HLCnV3G9itxm2gIACbu5vWSnWJJJvRaEbT15W+rtHQvdmLcEUL1WwqtQs91/7djespz/qohrVPhykDOUbkcw6dkLQPEutPb1AQB4/MwgrwI898Gd2plqQnLdPhdJrF1Za0S5A28CZ3lS5hqBJ7VaoZnAOFGsGpYwzA6xCLqnd+zmEJ31kfg1ql5DmCwcubVCaHurMiMtGBwwTa4dQQLVXiNgvKse3ReSYk3dwvbz9ShDWnsDb2/R0fsrNCET0X1DzdqSYdeRsDhRs/c72KWR0KTuh21D6xmet7eueeidP7uHDDDtPXk42t8v700Oxeix+Oxdmm1BAP4vrqF7umhv+ThiXnO0bmE20DR8lzG7FnyJ547RvX4yVjokWHYU4QStPClfecTVURucgi9k7zsKSF0RvKCvaSgLpPB2lrWvhBxq7Zju6+wXItZDr4X2WpLWu/ZaV2AXXrTWGhWvnf6+imBkMzO1Dewtvc5dYibG84wqe21gf8x3Le6+1q2ZdbuOW2DMfCDP3qYc3+Ot0LW1vIwZA3PhvhSmcw2Y0nAdF+8DkzWV3olIKYOmS4JaqKOzBBVNX4NjwCYHnNCLEABVJNn+baT3nN+ZF8m4HOvtBuwCq23B+l4P6dxF2SoCvqZKyQ+UfbFXUD9hodax39fK3J++1iDz3j19Ox2mMHW9quUyy5Q4hb7Ycw21FnyvRXbHlDw0/r2ErbZPs0wBu0ctPbXD4FkX7sixRmXlUMOzfewtqeZ61fGaSfUitWuv7117oMDXv/h+X+a8IGL7/PRrEhPCLdbpZCuz3tG535wGairEe5cNGFk0Lu827wwz6wvYydtDUW+zk6ia3k/rtXhQ660CeyxqENOcbaZpefA/wI91N0lr3eicmbvTbf5O7vOZaO41pUFDMZDK8/sIsrejWVVnWKSVUJ7rsx0a6+virqq3WU5qJ8kwVBt0DebL+SSOmb0Snb2bdreMAW/j/rqiJoeLM55BjndogKRm7wMBtfeehpKDrnbMYqH5DcfW1QjKQ5h9JU8lgWe5UBQ6FKMwlhnXi/lnsfW8N8PFtXAuMXJ654Pyx16V2sGzPC2BvbtzL0TNdfy+NyHmXlzeHUgXX8i7Jm16C41adUBy3VTtSS/M/Nwn2d6zT+ssJBoFbzVM9gIG8pqK7xWjXUSl+ZEla16XL+DMSNsRIoedWbqk315AG1Kgc09zmCTMmqR1i7U0U5QjPeXf7YWay5/M71VO45m5t8pzr9tAMpbDaFozk+WKUMLZy99ZVeGdMQGeRyD09D9iMMMotU63XqZ91qGp81VpmOSmzZB1fy0EscrL4Jq9cVqeJeUegroz7LBCrs33/w/RIAcO1z9fnQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.Image.Image image mode=L size=128x128 at 0x7FC627E2DC10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(Image.fromarray(np.uint8(noise_im_frame)).convert('L'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f189f7df-f3de-4af8-893e-c5de708038db",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
