{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2b25b451-e7e8-476a-8910-cf745809ef08",
   "metadata": {},
   "source": [
    "get T1 from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8f951d4e-51fb-4521-81cd-48eb1c5e2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\"\"\"Import from keras_preprocessing not from keras.preprocessing, because Keras may or maynot contain the features discussed here depending upon when you read this article, until the keras_preprocessed library is updated in Keras use the github version.\"\"\"\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "#from tensorflow.keras import optimizers #., optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#Importing all the relevant library\n",
    "%matplotlib inline\n",
    "import h5py, os\n",
    "#from functions import transforms as T\n",
    "#from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "#from functions import transforms as T \n",
    "#from functions.subsample import MaskFunc\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd8d08e5-d611-4b99-add9-02cc854a9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(train_data_path, val_data_path, test_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_val_test = ['train', 'val', 'test']\n",
    "    data_path = [train_data_path, val_data_path, test_data_path]\n",
    "      \n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_val_test[i]] = []\n",
    "        \n",
    "        which_data_path = data_path[i]\n",
    "        t1 = 0\n",
    "        t2 = 0\n",
    "        t2dot = 0\n",
    "        tr = 0\n",
    "        te = 0\n",
    "        alfa = 0\n",
    "        for fname in sorted(os.listdir(which_data_path + '/images')):\n",
    "            if fname != \".DS_Store\":\n",
    "\n",
    "            \n",
    "                subject_data_path = os.path.join(which_data_path + '/images', fname)\n",
    "                     \n",
    "                if not os.path.isfile(subject_data_path): continue \n",
    "            \n",
    "          #  im_frame = Image.open(subject_data_path)\n",
    "\n",
    "            #get information from text file\n",
    "            # this will return a tuple of root and extension\n",
    "                split_tup = os.path.splitext(fname)\n",
    "\n",
    "  \n",
    "            # extract the file name and extension\n",
    "                file_name = split_tup[0]\n",
    "                file_path = os.path.join(which_data_path + '/texts', file_name) + '.txt'\n",
    "                f = open(os.path.join(which_data_path + '/texts', file_name) + '.txt', 'r')\n",
    "                line = f.readlines()[1]\n",
    "            \n",
    "                fields = line.split(',')\n",
    "                t1 = float(fields[0])\n",
    "                t2 = float(fields[1])\n",
    "                t2dot = float(fields[2])\n",
    "              #  tr = int(fields[3])\n",
    "               # te = int(fields[4])\n",
    "              #  alfa = int(fields[5])\n",
    "                f.close()\n",
    "                \n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "                data_list[train_val_test[i]] += [(fname, t1)]\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e859bb9f-fa84-4609-bf9e-e2decd504740",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = load_data_path (\"data/train\", \"data/val\", \"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "81e6528b-7dbc-44ca-86f3-810e789cba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_list['train']\n",
    "val_data = data_list['val']\n",
    "test_data = data_list['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08aa5111-5a82-4237-ba6c-72ee17a69ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data, columns=['fnames', 'labels'])\n",
    "train_df['labels']= train_df['labels'].astype(float)\n",
    "train_df['labels'] = round(train_df['labels'], 3)\n",
    "train_df['labels']= train_df['labels'].astype(str)\n",
    "train_df['fnames']= train_df['fnames'].astype(str)\n",
    "val_df = pd.DataFrame(val_data, columns=['fnames', 'labels'])\n",
    "val_df['labels']= val_df['labels'].astype(float)\n",
    "val_df['labels'] = round(val_df['labels'], 3)\n",
    "val_df['labels']= val_df['labels'].astype(str)\n",
    "val_df['fnames']= val_df['fnames'].astype(str)\n",
    "test_df = pd.DataFrame(test_data, columns=['fnames', 'labels'])\n",
    "test_df['labels']= test_df['labels'].astype(float)\n",
    "test_df['labels'] = round(test_df['labels'], 3)\n",
    "test_df['labels']= test_df['labels'].astype(str)\n",
    "test_df['fnames']= test_df['fnames'].astype(str)\n",
    "labels = train_df.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ce8641ab-96af-4fea-8b4e-2b4e38f108a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = len(labels)\n",
    "num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a3c7e74a-edb4-4d1a-b1f4-52addf03c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of         fnames labels\n",
       "0        1.png    4.2\n",
       "1       10.png   0.65\n",
       "2      100.png    4.2\n",
       "3     1000.png    4.2\n",
       "4     1001.png    4.2\n",
       "...        ...    ...\n",
       "2785   995.png   0.65\n",
       "2786   996.png  0.315\n",
       "2787   997.png   0.65\n",
       "2788   998.png   0.47\n",
       "2789   999.png   0.47\n",
       "\n",
       "[2790 rows x 2 columns]>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "beca63cc-5587-4daf-b728-00942ebfa873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2790 validated image filenames belonging to 4 classes.\n",
      "Found 826 validated image filenames belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "      dataframe=train_df,\n",
    "      directory=\"./data/train/images/\",\n",
    "      x_col=\"fnames\",\n",
    "      y_col=\"labels\",\n",
    "      batch_size=64,\n",
    "      seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"categorical\",\n",
    "      target_size=(224,224))\n",
    "\n",
    "\n",
    "\n",
    "valid_generator=test_datagen.flow_from_dataframe(\n",
    "      dataframe=val_df,\n",
    "      directory=\"./data/val/images/\",\n",
    "      x_col=\"fnames\",\n",
    "      y_col=\"labels\",\n",
    "      batch_size=64,\n",
    "      seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"categorical\",\n",
    "     target_size=(224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "49c790a0-c070-46fc-a219-c03f065e41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 826 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_df,\n",
    "      directory=\"./data/test/images\",\n",
    "      x_col=\"fnames\",\n",
    "      batch_size=1,\n",
    "      seed=42,\n",
    "      shuffle=False,\n",
    "      class_mode=None,\n",
    "      target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "2a04b567-9c49-4fad-9bcd-000cb1a058a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.optimizers import SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d4403221-0e45-4cc5-9cc8-6e84aa7d76e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-12-14 09:47:06.945117: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(224,224,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_class, activation='sigmoid'))\n",
    "\n",
    "#opt = SGD(lr=0.001, momentum=0.9)\n",
    "opt =tf.keras.optimizers.RMSprop(lr=0.0001, decay=1e-6)\n",
    "model.compile(optimizer=opt,loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e5ee260d-ecc7-46a5-988f-9ca7b092e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 10 #100 #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b861c-1472-444a-a2ee-c158e0a96e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1844: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  warnings.warn('`Model.fit_generator` is deprecated and '\n",
      "2021-12-14 09:47:11.516386: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:116] None of the MLIR optimization passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      " 3/43 [=>............................] - ETA: 12:54 - loss: 0.6538 - accuracy: 0.3811"
     ]
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "history = model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=n_epochs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d2eba7-f3ca-4e0f-8238-2d8b1c212b53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "# list all data in history\n",
    "print(history.history.keys())\n",
    "# summarize history for accuracy\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()\n",
    "# summarize history for loss\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323567d-93a3-4500-b39a-a00318629079",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f169b3-9e88-43d7-9480-c17a80cb9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d306d73-b624-46e9-aaa3-dbcca93dd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = (pred >0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a65ff-7ab7-4ec6-a745-bbf13c9c73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "labels = train_generator.class_indices\n",
    "\n",
    "textfile = open(\"T1_labels.txt\", \"w\")\n",
    "for element in labels:\n",
    "    textfile.write(element + \"\\n\")\n",
    "textfile.close()\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(labels[index])\n",
    "    predictions.append(\",\".join(l))\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"T1results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385e1fa-c041-40a3-ad3a-c47482ed3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "raw",
   "id": "476521a0-bfa6-411f-9793-2fd3f3d8e161",
   "metadata": {},
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#load the image\n",
    "my_image = load_img('data/test/images/127.png', target_size=(224, 224))\n",
    "\n",
    "#preprocess the image\n",
    "my_image = img_to_array(my_image)\n",
    "my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n",
    "my_image = preprocess_input(my_image)\n",
    "\n",
    "#make the prediction\n",
    "prediction = model.predict(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1c30c92-b894-4711-a67e-0bf044228268",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "original = PIL.Image.open(\"data/test/images/100.png\")\n",
    "file_type = original.format\n",
    "\n",
    "original.save(\"testing/test.png\", format=\"png\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed903af-3ed6-445b-ad90-5300d4304062",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "original = PIL.Image.open(\"data/test/images/100.png\") # replace later with image input\n",
    "file_type = original.format\n",
    "\n",
    "original.save(\"testing/test.png\", format=\"png\")\n",
    "##########################\n",
    "testdata = []\n",
    "for fname in sorted(os.listdir('testing')):\n",
    "    if fname == \".DS_Store\": continue\n",
    "            \n",
    "    subject_data_path = os.path.join('testing', fname)                   \n",
    "    if not os.path.isfile(subject_data_path): continue          \n",
    "    testdata.append(fname)\n",
    "    \n",
    "df = pd.DataFrame(testdata, columns=['fnames'])\n",
    "df['fnames']= df['fnames'].astype(str)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "test_g=test_datagen.flow_from_dataframe(\n",
    "     dataframe= df,\n",
    "      directory=\"./testing\",\n",
    "      x_col=\"fnames\",\n",
    "      batch_size=1,\n",
    "      seed=42,\n",
    "      shuffle=False,\n",
    "      class_mode=None,\n",
    "      target_size=(224,224))\n",
    "STEP_SIZE_TEST=test_g.n//test_g.batch_size\n",
    "pred = model.predict_generator(test_g,\n",
    "                               steps=STEP_SIZE_TEST,\n",
    "                               verbose=1)\n",
    "pred_bool = (pred >0.5)\n",
    "predictions=[]\n",
    "#labels = train_generator.class_indices\n",
    "#labels = dict((v,k) for k,v in labels.items())\n",
    "labels = {}\n",
    "file1 = open('T1_labels.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    labels[count] = line.strip()\n",
    "    count += 1\n",
    "    \n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(labels[index])\n",
    "    predictions.append(\",\".join(l))\n",
    "    \n",
    "    \n",
    "if predictions[0] == '':\n",
    "    result = 0\n",
    "else:\n",
    "    result = float (predictions[0] )\n",
    "#result = float (predictions[0] ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fcfdb4-3241-4161-85cb-9d2a6cec1b4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86e81fe7-eaf1-4b6c-bb83-60163f2051ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06603d7a-be6f-4b00-a566-274256c1fbda",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f98c159d-64be-4d98-b12d-98ff511626a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "raw",
   "id": "2964a2d6-0d92-4019-b93e-f908bd728ac7",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('data/test/images/127.png', target_size =(224,224))\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "result = model.predict(test_image)\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fd6718b4-dc5f-4115-b886-424f6fcfe55d",
   "metadata": {},
   "source": [
    "test_image = image.load_img('data/test/images/228.png', target_size =(224,224))\n",
    "test_image = np.expand_dims(test_image,axis=0)\n",
    "test_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be769dfd-b348-4067-bb46-276897728b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "filename2 = 'model_t1.h5' \n",
    "model.save(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "607599c9-9b5d-44b2-a74a-95516d370e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# load model\n",
    "model = load_model('model_t1.h5')"
   ]
  },
  {
   "cell_type": "raw",
   "id": "652a1b62-1de5-4853-b3c4-d36882a6a62b",
   "metadata": {},
   "source": [
    "https://www.analyticsvidhya.com/blog/2020/10/create-image-classification-model-python-keras/"
   ]
  },
  {
   "cell_type": "raw",
   "id": "23e021e2-aaed-440a-bda5-a8b1b4e313fd",
   "metadata": {},
   "source": [
    "    def flow_from_dataframe(self,\n",
    "                            dataframe,\n",
    "                            directory=None,\n",
    "                            x_col=\"filename\",\n",
    "                            y_col=\"class\",\n",
    "                            weight_col=None,\n",
    "                            target_size=(256, 256),\n",
    "                            color_mode='rgb',\n",
    "                            classes=None,\n",
    "                            class_mode='categorical',\n",
    "                            batch_size=32,\n",
    "                            shuffle=True,\n",
    "                            seed=None,\n",
    "                            save_to_dir=None,\n",
    "                            save_prefix='',\n",
    "                            save_format='png',\n",
    "                            subset=None,\n",
    "                            interpolation='nearest',\n",
    "                            validate_filenames=True,\n",
    "                            **kwargs):\n",
    "        \"\"\"Takes the dataframe and the path to a directory\n",
    "         and generates batches of augmented/normalized data.\n",
    "        **A simple tutorial can be found **[here](\n",
    "                                    http://bit.ly/keras_flow_from_dataframe).\n",
    "        # Arguments\n",
    "            dataframe: Pandas dataframe containing the filepaths relative to\n",
    "                `directory` (or absolute paths if `directory` is None) of the\n",
    "                images in a string column. It should include other column/s\n",
    "                depending on the `class_mode`:\n",
    "                - if `class_mode` is `\"categorical\"` (default value) it must\n",
    "                    include the `y_col` column with the class/es of each image.\n",
    "                    Values in column can be string/list/tuple if a single class\n",
    "                    or list/tuple if multiple classes.\n",
    "                - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n",
    "                    the given `y_col` column with class values as strings.\n",
    "                - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n",
    "                the columns specified in `y_col`.\n",
    "                - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n",
    "            directory: string, path to the directory to read images from. If `None`,\n",
    "                data in `x_col` column should be absolute paths.\n",
    "            x_col: string, column in `dataframe` that contains the filenames (or\n",
    "                absolute paths if `directory` is `None`).\n",
    "            y_col: string or list, column/s in `dataframe` that has the target data.\n",
    "            weight_col: string, column in `dataframe` that contains the sample\n",
    "                weights. Default: `None`.\n",
    "            target_size: tuple of integers `(height, width)`, default: `(256, 256)`.\n",
    "                The dimensions to which all images found will be resized.\n",
    "            color_mode: one of \"grayscale\", \"rgb\", \"rgba\". Default: \"rgb\".\n",
    "                Whether the images will be converted to have 1 or 3 color channels.\n",
    "            classes: optional list of classes (e.g. `['dogs', 'cats']`).\n",
    "                Default: None. If not provided, the list of classes will be\n",
    "                automatically inferred from the `y_col`,\n",
    "                which will map to the label indices, will be alphanumeric).\n",
    "                The dictionary containing the mapping from class names to class\n",
    "                indices can be obtained via the attribute `class_indices`.\n",
    "            class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n",
    "                \"raw\", sparse\" or None. Default: \"categorical\".\n",
    "                Mode for yielding the targets:\n",
    "                - `\"binary\"`: 1D NumPy array of binary labels,\n",
    "                - `\"categorical\"`: 2D NumPy array of one-hot encoded labels.\n",
    "                    Supports multi-label output.\n",
    "                - `\"input\"`: images identical to input images (mainly used to\n",
    "                    work with autoencoders),\n",
    "                - `\"multi_output\"`: list with the values of the different columns,\n",
    "                - `\"raw\"`: NumPy array of values in `y_col` column(s),\n",
    "                - `\"sparse\"`: 1D NumPy array of integer labels,\n",
    "                - `None`, no targets are returned (the generator will only yield\n",
    "                    batches of image data, which is useful to use in\n",
    "                    `model.predict_generator()`).\n",
    "            batch_size: size of the batches of data (default: 32).\n",
    "            shuffle: whether to shuffle the data (default: True)\n",
    "            seed: optional random seed for shuffling and transformations.\n",
    "            save_to_dir: None or str (default: None).\n",
    "                This allows you to optionally specify a directory\n",
    "                to which to save the augmented pictures being generated\n",
    "                (useful for visualizing what you are doing).\n",
    "            save_prefix: str. Prefix to use for filenames of saved pictures\n",
    "                (only relevant if `save_to_dir` is set).\n",
    "            save_format: one of \"png\", \"jpeg\"\n",
    "                (only relevant if `save_to_dir` is set). Default: \"png\".\n",
    "            follow_links: whether to follow symlinks inside class subdirectories\n",
    "                (default: False).\n",
    "            subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "                `validation_split` is set in `ImageDataGenerator`.\n",
    "            interpolation: Interpolation method used to resample the image if the\n",
    "                target size is different from that of the loaded image.\n",
    "                Supported methods are `\"nearest\"`, `\"bilinear\"`, and `\"bicubic\"`.\n",
    "                If PIL version 1.1.3 or newer is installed, `\"lanczos\"` is also\n",
    "                supported. If PIL version 3.4.0 or newer is installed, `\"box\"` and\n",
    "                `\"hamming\"` are also supported. By default, `\"nearest\"` is used.\n",
    "            validate_filenames: Boolean, whether to validate image filenames in\n",
    "                `x_col`. If `True`, invalid images will be ignored. Disabling this\n",
    "                option can lead to speed-up in the execution of this function.\n",
    "                Default: `True`.\n",
    "        # Returns\n",
    "            A `DataFrameIterator` yielding tuples of `(x, y)`\n",
    "            where `x` is a NumPy array containing a batch\n",
    "            of images with shape `(batch_size, *target_size, channels)`\n",
    "            and `y` is a NumPy array of corresponding labels.\n",
    "        \"\"\"\n",
    "        if 'has_ext' in kwargs:\n",
    "            warnings.warn('has_ext is deprecated, filenames in the dataframe have '\n",
    "                          'to match the exact filenames in disk.',\n",
    "                          DeprecationWarning)\n",
    "        if 'sort' in kwargs:\n",
    "            warnings.warn('sort is deprecated, batches will be created in the'\n",
    "                          'same order than the filenames provided if shuffle'\n",
    "                          'is set to False.', DeprecationWarning)\n",
    "        if class_mode == 'other':\n",
    "            warnings.warn('`class_mode` \"other\" is deprecated, please use '\n",
    "                          '`class_mode` \"raw\".', DeprecationWarning)\n",
    "            class_mode = 'raw'\n",
    "        if 'drop_duplicates' in kwargs:\n",
    "            warnings.warn('drop_duplicates is deprecated, you can drop duplicates '\n",
    "                          'by using the pandas.DataFrame.drop_duplicates method.',\n",
    "                          DeprecationWarning)\n",
    "\n",
    "        return DataFrameIterator(\n",
    "            dataframe,\n",
    "            directory,\n",
    "            self,\n",
    "            x_col=x_col,\n",
    "            y_col=y_col,\n",
    "            weight_col=weight_col,\n",
    "            target_size=target_size,\n",
    "            color_mode=color_mode,\n",
    "            classes=classes,\n",
    "            class_mode=class_mode,\n",
    "            data_format=self.data_format,\n",
    "            batch_size=batch_size,\n",
    "            shuffle=shuffle,\n",
    "            seed=seed,\n",
    "            save_to_dir=save_to_dir,\n",
    "            save_prefix=save_prefix,\n",
    "            save_format=save_format,\n",
    "            subset=subset,\n",
    "            interpolation=interpolation,\n",
    "            validate_filenames=validate_filenames,\n",
    "            dtype=self.dtype\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0415ad83-e8ea-42f0-af3f-7c72baacf2fa",
   "metadata": {},
   "source": [
    "\"\"\"Utilities for real-time data augmentation on image data.\n",
    "\"\"\"\n",
    "import os\n",
    "import warnings\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from .iterator import BatchFromFilesMixin, Iterator\n",
    "from .utils import validate_filename\n",
    "\n",
    "\n",
    "class DataFrameIterator(BatchFromFilesMixin, Iterator):\n",
    "    \"\"\"Iterator capable of reading images from a directory on disk\n",
    "        through a dataframe.\n",
    "    # Arguments\n",
    "        dataframe: Pandas dataframe containing the filepaths relative to\n",
    "            `directory` (or absolute paths if `directory` is None) of the\n",
    "            images in a string column. It should include other column/s\n",
    "            depending on the `class_mode`:\n",
    "            - if `class_mode` is `\"categorical\"` (default value) it must\n",
    "                include the `y_col` column with the class/es of each image.\n",
    "                Values in column can be string/list/tuple if a single class\n",
    "                or list/tuple if multiple classes.\n",
    "            - if `class_mode` is `\"binary\"` or `\"sparse\"` it must include\n",
    "                the given `y_col` column with class values as strings.\n",
    "            - if `class_mode` is `\"raw\"` or `\"multi_output\"` it should contain\n",
    "                the columns specified in `y_col`.\n",
    "            - if `class_mode` is `\"input\"` or `None` no extra column is needed.\n",
    "        directory: string, path to the directory to read images from. If `None`,\n",
    "            data in `x_col` column should be absolute paths.\n",
    "        image_data_generator: Instance of `ImageDataGenerator` to use for\n",
    "            random transformations and normalization. If None, no transformations\n",
    "            and normalizations are made.\n",
    "        x_col: string, column in `dataframe` that contains the filenames (or\n",
    "            absolute paths if `directory` is `None`).\n",
    "        y_col: string or list, column/s in `dataframe` that has the target data.\n",
    "        weight_col: string, column in `dataframe` that contains the sample\n",
    "            weights. Default: `None`.\n",
    "        target_size: tuple of integers, dimensions to resize input images to.\n",
    "        color_mode: One of `\"rgb\"`, `\"rgba\"`, `\"grayscale\"`.\n",
    "            Color mode to read images.\n",
    "        classes: Optional list of strings, classes to use (e.g. `[\"dogs\", \"cats\"]`).\n",
    "            If None, all classes in `y_col` will be used.\n",
    "        class_mode: one of \"binary\", \"categorical\", \"input\", \"multi_output\",\n",
    "            \"raw\", \"sparse\" or None. Default: \"categorical\".\n",
    "            Mode for yielding the targets:\n",
    "            - `\"binary\"`: 1D numpy array of binary labels,\n",
    "            - `\"categorical\"`: 2D numpy array of one-hot encoded labels.\n",
    "                Supports multi-label output.\n",
    "            - `\"input\"`: images identical to input images (mainly used to\n",
    "                work with autoencoders),\n",
    "            - `\"multi_output\"`: list with the values of the different columns,\n",
    "            - `\"raw\"`: numpy array of values in `y_col` column(s),\n",
    "            - `\"sparse\"`: 1D numpy array of integer labels,\n",
    "            - `None`, no targets are returned (the generator will only yield\n",
    "                batches of image data, which is useful to use in\n",
    "                `model.predict_generator()`).\n",
    "        batch_size: Integer, size of a batch.\n",
    "        shuffle: Boolean, whether to shuffle the data between epochs.\n",
    "        seed: Random seed for data shuffling.\n",
    "        data_format: String, one of `channels_first`, `channels_last`.\n",
    "        save_to_dir: Optional directory where to save the pictures\n",
    "            being yielded, in a viewable format. This is useful\n",
    "            for visualizing the random transformations being\n",
    "            applied, for debugging purposes.\n",
    "        save_prefix: String prefix to use for saving sample\n",
    "            images (if `save_to_dir` is set).\n",
    "        save_format: Format to use for saving sample images\n",
    "            (if `save_to_dir` is set).\n",
    "        subset: Subset of data (`\"training\"` or `\"validation\"`) if\n",
    "            validation_split is set in ImageDataGenerator.\n",
    "        interpolation: Interpolation method used to resample the image if the\n",
    "            target size is different from that of the loaded image.\n",
    "            Supported methods are \"nearest\", \"bilinear\", and \"bicubic\".\n",
    "            If PIL version 1.1.3 or newer is installed, \"lanczos\" is also\n",
    "            supported. If PIL version 3.4.0 or newer is installed, \"box\" and\n",
    "            \"hamming\" are also supported. By default, \"nearest\" is used.\n",
    "        keep_aspect_ratio: Boolean, whether to resize images to a target size\n",
    "            without aspect ratio distortion. The image is cropped in the center\n",
    "            with target aspect ratio before resizing.\n",
    "        dtype: Dtype to use for the generated arrays.\n",
    "        validate_filenames: Boolean, whether to validate image filenames in\n",
    "        `x_col`. If `True`, invalid images will be ignored. Disabling this option\n",
    "        can lead to speed-up in the instantiation of this class. Default: `True`.\n",
    "    \"\"\"\n",
    "    allowed_class_modes = {\n",
    "        'binary', 'categorical', 'input', 'multi_output', 'raw', 'sparse', None\n",
    "    }\n",
    "\n",
    "    def __new__(cls, *args, **kwargs):\n",
    "        try:\n",
    "            from tensorflow.keras.utils import Sequence as TFSequence\n",
    "            if TFSequence not in cls.__bases__:\n",
    "                cls.__bases__ = cls.__bases__ + (TFSequence,)\n",
    "        except ImportError:\n",
    "            pass\n",
    "        return super(DataFrameIterator, cls).__new__(cls)\n",
    "\n",
    "    def __init__(self,\n",
    "                 dataframe,\n",
    "                 directory=None,\n",
    "                 image_data_generator=None,\n",
    "                 x_col=\"filename\",\n",
    "                 y_col=\"class\",\n",
    "                 weight_col=None,\n",
    "                 target_size=(256, 256),\n",
    "                 color_mode='rgb',\n",
    "                 classes=None,\n",
    "                 class_mode='categorical',\n",
    "                 batch_size=32,\n",
    "                 shuffle=True,\n",
    "                 seed=None,\n",
    "                 data_format='channels_last',\n",
    "                 save_to_dir=None,\n",
    "                 save_prefix='',\n",
    "                 save_format='png',\n",
    "                 subset=None,\n",
    "                 interpolation='nearest',\n",
    "                 keep_aspect_ratio=False,\n",
    "                 dtype='float32',\n",
    "                 validate_filenames=True):\n",
    "\n",
    "        super(DataFrameIterator, self).set_processing_attrs(image_data_generator,\n",
    "                                                            target_size,\n",
    "                                                            color_mode,\n",
    "                                                            data_format,\n",
    "                                                            save_to_dir,\n",
    "                                                            save_prefix,\n",
    "                                                            save_format,\n",
    "                                                            subset,\n",
    "                                                            interpolation,\n",
    "                                                            keep_aspect_ratio)\n",
    "        df = dataframe.copy()\n",
    "        self.directory = directory or ''\n",
    "        self.class_mode = class_mode\n",
    "        self.dtype = dtype\n",
    "        # check that inputs match the required class_mode\n",
    "        self._check_params(df, x_col, y_col, weight_col, classes)\n",
    "        if validate_filenames:  # check which image files are valid and keep them\n",
    "            df = self._filter_valid_filepaths(df, x_col)\n",
    "        if class_mode not in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            df, classes = self._filter_classes(df, y_col, classes)\n",
    "            num_classes = len(classes)\n",
    "            # build an index of all the unique classes\n",
    "            self.class_indices = dict(zip(classes, range(len(classes))))\n",
    "        # retrieve only training or validation set\n",
    "        if self.split:\n",
    "            num_files = len(df)\n",
    "            start = int(self.split[0] * num_files)\n",
    "            stop = int(self.split[1] * num_files)\n",
    "            df = df.iloc[start: stop, :]\n",
    "        # get labels for each observation\n",
    "        if class_mode not in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            self.classes = self.get_classes(df, y_col)\n",
    "        self.filenames = df[x_col].tolist()\n",
    "        self._sample_weight = df[weight_col].values if weight_col else None\n",
    "\n",
    "        if class_mode == \"multi_output\":\n",
    "            self._targets = [np.array(df[col].tolist()) for col in y_col]\n",
    "        if class_mode == \"raw\":\n",
    "            self._targets = df[y_col].values\n",
    "        self.samples = len(self.filenames)\n",
    "        validated_string = 'validated' if validate_filenames else 'non-validated'\n",
    "        if class_mode in [\"input\", \"multi_output\", \"raw\", None]:\n",
    "            print('Found {} {} image filenames.'\n",
    "                  .format(self.samples, validated_string))\n",
    "        else:\n",
    "            print('Found {} {} image filenames belonging to {} classes.'\n",
    "                  .format(self.samples, validated_string, num_classes))\n",
    "        self._filepaths = [\n",
    "            os.path.join(self.directory, fname) for fname in self.filenames\n",
    "        ]\n",
    "        super(DataFrameIterator, self).__init__(self.samples,\n",
    "                                                batch_size,\n",
    "                                                shuffle,\n",
    "                                                seed)\n",
    "\n",
    "    def _check_params(self, df, x_col, y_col, weight_col, classes):\n",
    "        # check class mode is one of the currently supported\n",
    "        if self.class_mode not in self.allowed_class_modes:\n",
    "            raise ValueError('Invalid class_mode: {}; expected one of: {}'\n",
    "                             .format(self.class_mode, self.allowed_class_modes))\n",
    "        # check that y_col has several column names if class_mode is multi_output\n",
    "        if (self.class_mode == 'multi_output') and not isinstance(y_col, list):\n",
    "            raise TypeError(\n",
    "                'If class_mode=\"{}\", y_col must be a list. Received {}.'\n",
    "                .format(self.class_mode, type(y_col).__name__)\n",
    "            )\n",
    "        # check that filenames/filepaths column values are all strings\n",
    "        if not all(df[x_col].apply(lambda x: isinstance(x, str))):\n",
    "            raise TypeError('All values in column x_col={} must be strings.'\n",
    "                            .format(x_col))\n",
    "        # check labels are string if class_mode is binary or sparse\n",
    "        if self.class_mode in {'binary', 'sparse'}:\n",
    "            if not all(df[y_col].apply(lambda x: isinstance(x, str))):\n",
    "                raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n",
    "                                'values must be strings.'\n",
    "                                .format(self.class_mode, y_col))\n",
    "        # check that if binary there are only 2 different classes\n",
    "        if self.class_mode == 'binary':\n",
    "            if classes:\n",
    "                classes = set(classes)\n",
    "                if len(classes) != 2:\n",
    "                    raise ValueError('If class_mode=\"binary\" there must be 2 '\n",
    "                                     'classes. {} class/es were given.'\n",
    "                                     .format(len(classes)))\n",
    "            elif df[y_col].nunique() != 2:\n",
    "                raise ValueError('If class_mode=\"binary\" there must be 2 classes. '\n",
    "                                 'Found {} classes.'.format(df[y_col].nunique()))\n",
    "        # check values are string, list or tuple if class_mode is categorical\n",
    "        if self.class_mode == 'categorical':\n",
    "            types = (str, list, tuple)\n",
    "            if not all(df[y_col].apply(lambda x: isinstance(x, types))):\n",
    "                raise TypeError('If class_mode=\"{}\", y_col=\"{}\" column '\n",
    "                                'values must be type string, list or tuple.'\n",
    "                                .format(self.class_mode, y_col))\n",
    "        # raise warning if classes are given but will be unused\n",
    "        if classes and self.class_mode in {\"input\", \"multi_output\", \"raw\", None}:\n",
    "            warnings.warn('`classes` will be ignored given the class_mode=\"{}\"'\n",
    "                          .format(self.class_mode))\n",
    "        # check that if weight column that the values are numerical\n",
    "        if weight_col and not issubclass(df[weight_col].dtype.type, np.number):\n",
    "            raise TypeError('Column weight_col={} must be numeric.'\n",
    "                            .format(weight_col))\n",
    "\n",
    "    def get_classes(self, df, y_col):\n",
    "        labels = []\n",
    "        for label in df[y_col]:\n",
    "            if isinstance(label, (list, tuple)):\n",
    "                labels.append([self.class_indices[lbl] for lbl in label])\n",
    "            else:\n",
    "                labels.append(self.class_indices[label])\n",
    "        return labels\n",
    "\n",
    "    @staticmethod\n",
    "    def _filter_classes(df, y_col, classes):\n",
    "        df = df.copy()\n",
    "\n",
    "        def remove_classes(labels, classes):\n",
    "            if isinstance(labels, (list, tuple)):\n",
    "                labels = [cls for cls in labels if cls in classes]\n",
    "                return labels or None\n",
    "            elif isinstance(labels, str):\n",
    "                return labels if labels in classes else None\n",
    "            else:\n",
    "                raise TypeError(\n",
    "                    \"Expect string, list or tuple but found {} in {} column \"\n",
    "                    .format(type(labels), y_col)\n",
    "                )\n",
    "\n",
    "        if classes:\n",
    "            # prepare for membership lookup\n",
    "            classes = list(OrderedDict.fromkeys(classes).keys())\n",
    "            df[y_col] = df[y_col].apply(lambda x: remove_classes(x, classes))\n",
    "        else:\n",
    "            classes = set()\n",
    "            for v in df[y_col]:\n",
    "                if isinstance(v, (list, tuple)):\n",
    "                    classes.update(v)\n",
    "                else:\n",
    "                    classes.add(v)\n",
    "            classes = sorted(classes)\n",
    "        return df.dropna(subset=[y_col]), classes\n",
    "\n",
    "    def _filter_valid_filepaths(self, df, x_col):\n",
    "        \"\"\"Keep only dataframe rows with valid filenames\n",
    "        # Arguments\n",
    "            df: Pandas dataframe containing filenames in a column\n",
    "            x_col: string, column in `df` that contains the filenames or filepaths\n",
    "        # Returns\n",
    "            absolute paths to image files\n",
    "        \"\"\"\n",
    "        filepaths = df[x_col].map(\n",
    "            lambda fname: os.path.join(self.directory, fname)\n",
    "        )\n",
    "        mask = filepaths.apply(validate_filename, args=(self.white_list_formats,))\n",
    "        n_invalid = (~mask).sum()\n",
    "        if n_invalid:\n",
    "            warnings.warn(\n",
    "                'Found {} invalid image filename(s) in x_col=\"{}\". '\n",
    "                'These filename(s) will be ignored.'\n",
    "                .format(n_invalid, x_col)\n",
    "            )\n",
    "        return df[mask]\n",
    "\n",
    "    @property\n",
    "    def filepaths(self):\n",
    "        return self._filepaths\n",
    "\n",
    "    @property\n",
    "    def labels(self):\n",
    "        if self.class_mode in {\"multi_output\", \"raw\"}:\n",
    "            return self._targets\n",
    "        else:\n",
    "            return self.classes\n",
    "\n",
    "    @property\n",
    "    def sample_weight(self):\n",
    "        return self._sample_weight"
   ]
  },
  {
   "cell_type": "raw",
   "id": "1f606ee1-be74-4bad-8ac7-7f71faf4010b",
   "metadata": {},
   "source": [
    "https://github.com/keras-team/keras-preprocessing/blob/master/keras_preprocessing/image/iterator.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f72d1523-4ca2-4bfa-9cf5-1a2a5dc652ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df['labels'].astype(str)\n",
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19a8004a-07d0-47b6-8b87-2d70c9c5b0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test_df['labels'].astype(str)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255.)\n",
    "test_g=test_datagen.flow_from_dataframe(\n",
    "     dataframe= test_df,\n",
    "      directory=\"./data/test/images\",\n",
    "      x_col=\"fnames\",\n",
    "      batch_size=1,\n",
    "      seed=42,\n",
    "      shuffle=False,\n",
    "      class_mode=None,\n",
    "      target_size=(224,224)) # to avoid loss of information\n",
    "STEP_SIZE_TEST=test_g.n//test_g.batch_size\n",
    "pred = model.predict_generator(test_g,\n",
    "                               steps=STEP_SIZE_TEST,\n",
    "                               verbose=1)\n",
    "pred_bool = (pred >0.5)\n",
    "predictions=[]\n",
    "#labels = train_generator.class_indices\n",
    "#labels = dict((v,k) for k,v in labels.items())\n",
    "labels = {}\n",
    "file1 = open('T1_labels.txt', 'r')\n",
    "Lines = file1.readlines()\n",
    " \n",
    "count = 0\n",
    "# Strips the newline character\n",
    "for line in Lines:\n",
    "    labels[count] = line.strip()\n",
    "    count += 1\n",
    "    \n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(labels[index])\n",
    "      \n",
    "    predictions.append(\",\".join(l))\n",
    "y_pred =[]\n",
    "for i in range(0, len(predictions)):\n",
    "    if predictions[i] == '':\n",
    "        y_pred.append(0)\n",
    "    else:\n",
    "        listValue  = list(map(float, predictions[i].split(',')))\n",
    "\n",
    "        y_pred.append(str(round(max(listValue), 2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ad7c55a-c4f7-4cd3-af03-cf211b9ff8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "570e050f-8dff-4525-afb8-fd27e125284a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aee961c0-0365-415e-919f-e1a38ffe7d85",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Importing all necessary libraries\n",
    "from sklearn.metrics import accuracy_score\n",
    "# Calculating the accuracy of classifier\n",
    "print(f\"Accuracy of the classifier is: {accuracy_score(y_test, y_pred)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e89f057-c665-4817-8826-e445e6095dc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# confusion_matrix funnction a matrix containing the summary of predictions\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56df3dab-ec0f-4d8a-95ef-00f2d6641a8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "  # Calculation of Mean Squared Error (MSE)\n",
    "mean_squared_error([float(i) for i in y_test], [float(i) for i in y_pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d7ac7c1-c7f8-49b2-857f-4b8b9bff395e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
