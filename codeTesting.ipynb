{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b348c738-5676-44cb-ae94-c6f9a2810265",
   "metadata": {},
   "source": [
    "# Machine Learning- reconstruct Image from partial/incomplete image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "19a9d273-16b9-41c9-a95f-1c15a875adf5",
   "metadata": {},
   "source": [
    "https://github.com/simontomaskarlsson/GAN-MRI\n",
    "\n",
    "https://github.com/puneesh00/cs-mri-gan\n",
    "\n",
    "https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391\n",
    "\n",
    "https://medium.com/howtoai/gan-for-medical-imaging-generating-images-and-annotations-8ad7c778809c\n",
    "\n",
    "\n",
    "https://github.com/birogeri/kspace-explorer\n",
    "\n",
    "\n",
    "https://medium.com/@vivek8981/dicom-to-jpg-and-extract-all-patients-information-using-python-5e6dd1f1a07d"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8bb1f397-0fed-4610-8414-e619719cb356",
   "metadata": {},
   "source": [
    "conda install -c bioconda medpy\n",
    "conda install -c conda-forge nibabel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00379251-4592-4c14-8cf6-46af2ab618eb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d4597d8-f02e-41a3-b2e0-9bcdf5214982",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d8dc33-e593-4bb6-9896-efacc2aa0486",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0654ab55-34ac-4552-b769-6d985ad316e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "995621a2-ef6a-4d94-98da-15f7f13240f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Layer, Input, Conv2D, Activation, add, BatchNormalization, UpSampling2D, ZeroPadding2D, Conv2DTranspose, Flatten, MaxPooling2D, AveragePooling2D\n",
    "from keras_contrib.layers.normalization import InstanceNormalization, InputSpec\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers.core import Dense\n",
    "from keras.optimizers import Adam\n",
    "from keras.backend import mean\n",
    "from keras.models import Model, model_from_json\n",
    "from keras.utils import plot_model\n",
    "from keras.engine.topology import Container\n",
    "\n",
    "from collections import OrderedDict\n",
    "from scipy.misc import imsave, toimage  # has depricated\n",
    "import numpy as np\n",
    "import random\n",
    "import datetime\n",
    "import time\n",
    "import json\n",
    "import math\n",
    "import csv\n",
    "import sys\n",
    "import os\n",
    "\n",
    "import keras.backend as K\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0b92a1ad-7314-47d1-93c4-7310f2b47d28",
   "metadata": {},
   "source": [
    "1. Collect K-Space for medical Images (MRI preferred)\n",
    "\n",
    "2. Remove some of the region of K-Space and destroy the image\n",
    "\n",
    "3. Use the destroyed image to reconstruct the original image using deep neural networks\n",
    "\n",
    "4. Define evaluation metrics\n",
    "\n",
    "5. Analyze the quality of your reconstructio"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f24fcbca-4fc9-4b25-889a-4ae2bb85d39d",
   "metadata": {},
   "source": [
    "## 1/ Extract information from incomplete image"
   ]
  },
  {
   "cell_type": "raw",
   "id": "52da2f7f-ba93-4d34-bf16-47f0313f9365",
   "metadata": {},
   "source": [
    "Citation, DOI and article data\n",
    "k-space is an abstract concept and refers to a data matrix containing the raw MRI data. This data is subjected to mathematical function or formula called a transform to generate the final image. A discrete Fourier or fast Fourier transform 1-3 is generally used though other transforms such as the Hartley 4 can also work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4372d201-d4ed-4957-905b-3a87df2d8dcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numpy.fft import fftshift, ifftshift, fftn, ifftn\n",
    "\n",
    "def transform_kspace_to_image(k, dim=None, img_shape=None):\n",
    "    \"\"\" Computes the Fourier transform from k-space to image space\n",
    "    along a given or all dimensions\n",
    "    :param k: k-space data\n",
    "    :param dim: vector of dimensions to transform\n",
    "    :param img_shape: desired shape of output image\n",
    "    :returns: data in image space (along transformed dimensions)\n",
    "    \"\"\"\n",
    "    if not dim:\n",
    "        dim = range(k.ndim)\n",
    "\n",
    "    img = fftshift(ifftn(ifftshift(k, axes=dim), s=img_shape, axes=dim), axes=dim)\n",
    "    img *= np.sqrt(np.prod(np.take(img.shape, dim)))\n",
    "    return img\n",
    "\n",
    "\n",
    "def transform_image_to_kspace(img, dim=None, k_shape=None):\n",
    "    \"\"\" Computes the Fourier transform from image space to k-space space\n",
    "    along a given or all dimensions\n",
    "    :param img: image space data\n",
    "    :param dim: vector of dimensions to transform\n",
    "    :param k_shape: desired shape of output k-space data\n",
    "    :returns: data in k-space (along transformed dimensions)\n",
    "    \"\"\"\n",
    "    if not dim:\n",
    "        dim = range(img.ndim)\n",
    "\n",
    "    k = fftshift(fftn(ifftshift(img, axes=dim), s=k_shape, axes=dim), axes=dim)\n",
    "    k /= np.sqrt(np.prod(np.take(img.shape, dim)))\n",
    "    return k"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a5c3e22-3bac-4bc3-bde8-63218076067c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73f6ea09-df3e-4b68-ba6c-8da4b70cdb99",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = nib.load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7c32d2-3104-4317-b7c5-72067adba2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22a8ff89-c7d9-4ae1-922f-6b8e80c9df19",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1326da13-6e7e-4985-a97e-81e046c8e16a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0b8cbb-c4fe-4966-a52f-b9d6facca281",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6c0427-a9ca-4b77-913f-b786eda1c925",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "from keras.utils import Sequence\n",
    "#from skimage.io import imread\n",
    "\n",
    "\n",
    "def load_data(nr_of_channels, batch_size=1, nr_A_train_imgs=None, nr_B_train_imgs=None,\n",
    "              nr_A_test_imgs=None, nr_B_test_imgs=None, subfolder='',\n",
    "              generator=False, D_model=None, use_multiscale_discriminator=False, use_supervised_learning=False, REAL_LABEL=1.0):\n",
    "\n",
    "    trainA_path = os.path.join('data', subfolder, 'trainA')\n",
    "    trainB_path = os.path.join('data', subfolder, 'trainB')\n",
    "    testA_path = os.path.join('data', subfolder, 'testA')\n",
    "    testB_path = os.path.join('data', subfolder, 'testB')\n",
    "\n",
    "    trainA_image_names = os.listdir(trainA_path)\n",
    "    if nr_A_train_imgs != None:\n",
    "        trainA_image_names = trainA_image_names[:nr_A_train_imgs]\n",
    "\n",
    "    trainB_image_names = os.listdir(trainB_path)\n",
    "    if nr_B_train_imgs != None:\n",
    "        trainB_image_names = trainB_image_names[:nr_B_train_imgs]\n",
    "\n",
    "    testA_image_names = os.listdir(testA_path)\n",
    "    if nr_A_test_imgs != None:\n",
    "        testA_image_names = testA_image_names[:nr_A_test_imgs]\n",
    "\n",
    "    testB_image_names = os.listdir(testB_path)\n",
    "    if nr_B_test_imgs != None:\n",
    "        testB_image_names = testB_image_names[:nr_B_test_imgs]\n",
    "\n",
    "    if generator:\n",
    "        return data_sequence(trainA_path, trainB_path, trainA_image_names, trainB_image_names, batch_size=batch_size)  # D_model, use_multiscale_discriminator, use_supervised_learning, REAL_LABEL)\n",
    "    else:\n",
    "        trainA_images = create_image_array(trainA_image_names, trainA_path, nr_of_channels)\n",
    "        trainB_images = create_image_array(trainB_image_names, trainB_path, nr_of_channels)\n",
    "        testA_images = create_image_array(testA_image_names, testA_path, nr_of_channels)\n",
    "        testB_images = create_image_array(testB_image_names, testB_path, nr_of_channels)\n",
    "        return {\"trainA_images\": trainA_images, \"trainB_images\": trainB_images,\n",
    "                \"testA_images\": testA_images, \"testB_images\": testB_images,\n",
    "                \"trainA_image_names\": trainA_image_names,\n",
    "                \"trainB_image_names\": trainB_image_names,\n",
    "                \"testA_image_names\": testA_image_names,\n",
    "                \"testB_image_names\": testB_image_names}\n",
    "\n",
    "\n",
    "def create_image_array(image_list, image_path, nr_of_channels):\n",
    "    image_array = []\n",
    "    for image_name in image_list:\n",
    "        if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
    "            if nr_of_channels == 1:  # Gray scale image -> MR image\n",
    "                image = np.array(Image.open(os.path.join(image_path, image_name)))\n",
    "                image = image[:, :, np.newaxis]\n",
    "            else:                   # RGB image -> 3 channels\n",
    "                image = np.array(Image.open(os.path.join(image_path, image_name)))\n",
    "            image = normalize_array(image)\n",
    "            image_array.append(image)\n",
    "\n",
    "    return np.array(image_array)\n",
    "  \n",
    "  \n",
    "  # If using 16 bit depth images, use the formula 'array = array / 32767.5 - 1' instead\n",
    "def normalize_array(array):\n",
    "    array = array / 127.5 - 1\n",
    "    return array\n",
    "\n",
    "\n",
    "class data_sequence(Sequence):\n",
    "\n",
    "    def __init__(self, trainA_path, trainB_path, image_list_A, image_list_B, batch_size=1):  # , D_model, use_multiscale_discriminator, use_supervised_learning, REAL_LABEL):\n",
    "        self.batch_size = batch_size\n",
    "        self.train_A = []\n",
    "        self.train_B = []\n",
    "        for image_name in image_list_A:\n",
    "            if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
    "                self.train_A.append(os.path.join(trainA_path, image_name))\n",
    "        for image_name in image_list_B:\n",
    "            if image_name[-1].lower() == 'g':  # to avoid e.g. thumbs.db files\n",
    "                self.train_B.append(os.path.join(trainB_path, image_name))\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(max(len(self.train_A), len(self.train_B)) / float(self.batch_size))\n",
    "\n",
    "    def __getitem__(self, idx):  # , use_multiscale_discriminator, use_supervised_learning):if loop_index + batch_size >= min_nr_imgs:\n",
    "        if idx >= min(len(self.train_A), len(self.train_B)):\n",
    "            # If all images soon are used for one domain,\n",
    "            # randomly pick from this domain\n",
    "            if len(self.train_A) <= len(self.train_B):\n",
    "                indexes_A = np.random.randint(len(self.train_A), size=self.batch_size)\n",
    "                batch_A = []\n",
    "                for i in indexes_A:\n",
    "                    batch_A.append(self.train_A[i])\n",
    "                batch_B = self.train_B[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            else:\n",
    "                indexes_B = np.random.randint(len(self.train_B), size=self.batch_size)\n",
    "                batch_B = []\n",
    "                for i in indexes_B:\n",
    "                    batch_B.append(self.train_B[i])\n",
    "                batch_A = self.train_A[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "        else:\n",
    "            batch_A = self.train_A[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "            batch_B = self.train_B[idx * self.batch_size:(idx + 1) * self.batch_size]\n",
    "\n",
    "        real_images_A = create_image_array(batch_A, '', 3)\n",
    "        real_images_B = create_image_array(batch_B, '', 3)\n",
    "\n",
    "        return real_images_A, real_images_B  # input_data, target_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dbccb94-3aea-4a8d-a84f-50d6e4a7c580",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractInformation(image):\n",
    "    cv2\n",
    "    return"
   ]
  },
  {
   "cell_type": "raw",
   "id": "393b2549-e879-4988-86ec-a032e6a90bd6",
   "metadata": {},
   "source": [
    "import sys\n",
    "import pathlib\n",
    "from uuid import uuid4\n",
    "\n",
    "import numpy as np\n",
    "import pydicom\n",
    "from pydicom import errors\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "# Attempting to use mkl_fft (faster FFT library for Intel CPUs). Fallback is np\n",
    "try:\n",
    "    import mkl_fft as m\n",
    "\n",
    "    fft2 = m.fft2\n",
    "    ifft2 = m.ifft2\n",
    "except (ModuleNotFoundError, ImportError):\n",
    "    fft2 = np.fft.fft2\n",
    "    ifft2 = np.fft.ifft2\n",
    "finally:\n",
    "    fftshift = np.fft.fftshift\n",
    "    ifftshift = np.fft.ifftshift\n",
    "\n",
    "\n",
    "def open_file(path: str, dtype: np.dtype = np.float32) -> np.ndarray:\n",
    "    \"\"\"Tries to load image data into a NumPy ndarray\n",
    "    The function first tries to use the PIL Image library to identify and load\n",
    "    the image. PIL will convert the image to 8-bit pixels, black and white.\n",
    "    If PIL fails pydicom is the next choice.\n",
    "    Parameters:\n",
    "        path (str): The image file location\n",
    "        dtype (np.dtype): image array dtype (eg. np.float64)\n",
    "    Returns:\n",
    "        np.ndarray: a floating point NumPy ndarray of the specified dtype\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        with Image.open(path) as f:\n",
    "            img_file = f.convert('F')  # 'F' mode: 32-bit floating point pixels\n",
    "            img_pixel_array = np.array(img_file).astype(dtype)\n",
    "        return img_pixel_array\n",
    "    except FileNotFoundError:\n",
    "        raise\n",
    "    except OSError:\n",
    "        try:\n",
    "            with pydicom.dcmread(path) as dcm_file:\n",
    "                img_pixel_array = dcm_file.pixel_array.astype(dtype)\n",
    "            img_pixel_array.setflags(write=True)\n",
    "            return img_pixel_array\n",
    "        except errors.InvalidDicomError:\n",
    "            try:\n",
    "                raw_data = np.load(path)\n",
    "                return raw_data\n",
    "            except Exception as e:\n",
    "                raise e\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c6cbf42c-54f7-4bf0-94fa-0af9c2503449",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/ipykernel_launcher.py:14: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fba3a79a590>]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "mx = np.zeros([256,1])\n",
    "mx[96:128+32] = 1\n",
    "plt.plot(mx)\n",
    "\n",
    "ksp = np.fft.fft(mx,axis=0)\n",
    "plt.plot(np.abs(ksp))\n",
    "\n",
    "k = np.zeros(ksp.shape);\n",
    "\n",
    "# voxel #2 and #3 were mis-placed using an imperfect gradient \n",
    "k[3] = ksp[3]+ksp[2]; \n",
    "\n",
    "rec = np.fft.ifft(k,axis=0);\n",
    "phase = np.angle(rec)\n",
    "# it's a straight line after unwrapping\n",
    "plt.plot(np.angle(rec)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc85b8ae-20f7-42ff-bf06-9eeb0f0a34a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydicom as dicom\n",
    "import PIL # optional\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# specify your image path\n",
    "image_path = 'xray.dcm'\n",
    "ds = dicom.dcmread(image_path)\n",
    "plt.imshow( ds.pixel_array)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "raw",
   "id": "95f33441-22eb-4ceb-91a0-a92a0ab97a67",
   "metadata": {},
   "source": [
    "import pydicom as dicom\n",
    "import os\n",
    "import PIL # optional\n",
    "import pandas as pd\n",
    "import csv\n",
    "# list of attributes available in dicom image\n",
    "# download this file from the given github link\n",
    "dicom_image_description = pd.read_csv(\"dicom_image_description.csv\")\n",
    "# Specify the .dcm folder path\n",
    "folder_path = \"stage_1_test_images\"\n",
    "images_path = os.listdir(folder_path)\n",
    "# Patient's information will be stored in working directory #'Patient_Detail.csv'\n",
    "with open('Patient_Detail.csv', 'w', newline ='') as csvfile:\n",
    "    fieldnames = list(dicom_image_description[\"Description\"])\n",
    "    writer = csv.writer(csvfile, delimiter=',')\n",
    "    writer.writerow(fieldnames)\n",
    "    for n, image in enumerate(images_path):\n",
    "        ds = dicom.dcmread(os.path.join(folder_path, image))\n",
    "        rows = []\n",
    "        for field in fieldnames:\n",
    "            if ds.data_element(field) is None:\n",
    "                rows.append('')\n",
    "            else:\n",
    "                x = str(ds.data_element(field)).replace(\"'\", \"\")\n",
    "                y = x.find(\":\")\n",
    "                x = x[y+2:]\n",
    "                rows.append(x)\n",
    "        writer.writerow(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0152563a-4232-46b2-bc6e-15e8a2376be0",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14e1cf42-8373-4ea4-a25a-4510203b87c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "e662e182-7219-407f-b4ac-48bd19821054",
   "metadata": {},
   "source": [
    "2. Remove some of the region of K-Space and destroy the image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dd8fc22-d258-4721-8365-d5a5cd73e7d3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "eda16910-1d9b-4248-8860-0ec0fac1f1bf",
   "metadata": {},
   "source": [
    "3. Use the destroyed image to reconstruct the original image using deep neural networks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c995c74-2d38-48a8-a42b-ecf7d0163b80",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a9500-6804-4998-8ce3-f817f8e4952c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
