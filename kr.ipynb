{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2b25b451-e7e8-476a-8910-cf745809ef08",
   "metadata": {},
   "source": [
    "get KR from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f951d4e-51fb-4521-81cd-48eb1c5e2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\"\"\"Import from keras_preprocessing not from keras.preprocessing, because Keras may or maynot contain the features discussed here depending upon when you read this article, until the keras_preprocessed library is updated in Keras use the github version.\"\"\"\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#Importing all the relevant library\n",
    "%matplotlib inline\n",
    "import h5py, os\n",
    "#from functions import transforms as T\n",
    "#from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "#from functions import transforms as T \n",
    "#from functions.subsample import MaskFunc\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd8d08e5-d611-4b99-add9-02cc854a9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(train_data_path, val_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_and_val = ['train', 'val']\n",
    "    data_path = [train_data_path, val_data_path]\n",
    "      \n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_and_val[i]] = []\n",
    "        \n",
    "        which_data_path = data_path[i]\n",
    "        tr = 0\n",
    "        te = 0\n",
    "        alfa = 0\n",
    "        for fname in sorted(os.listdir(which_data_path + '/images')):\n",
    "            \n",
    "            subject_data_path = os.path.join(which_data_path + '/images', fname)\n",
    "                     \n",
    "            if not os.path.isfile(subject_data_path): continue \n",
    "            \n",
    "            im_frame = Image.open(subject_data_path)\n",
    "\n",
    "            #get information from text file\n",
    "            # this will return a tuple of root and extension\n",
    "            split_tup = os.path.splitext(fname)\n",
    "\n",
    "  \n",
    "            # extract the file name and extension\n",
    "            file_name = split_tup[0]\n",
    "            f = open(os.path.join(which_data_path + '/texts', file_name) + '.txt', 'r')\n",
    "\n",
    "            for line in f.readlines():\n",
    "                fields = line.split(',')\n",
    "                tr = int(fields[1])\n",
    "                te = int(fields[2])\n",
    "                alfa = int(fields[3])\n",
    "                f.close()\n",
    "                \n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "            data_list[train_and_val[i]] += [(im_frame, fname, tr)]\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e859bb9f-fa84-4609-bf9e-e2decd504740",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = load_data_path (\"train data path\", \"valid data path\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81e6528b-7dbc-44ca-86f3-810e789cba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_list['train']\n",
    "val_data = data_list['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08aa5111-5a82-4237-ba6c-72ee17a69ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data, columns=['image', 'fnames', 'labels'])\n",
    "val_df = pd.DataFrame(val_data, columns=['image', 'fnames', 'labels'])\n",
    "labels = train_df.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "beca63cc-5587-4daf-b728-00942ebfa873",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "      dataframe=train_df,\n",
    "      directory=\"./data/images\",\n",
    "      x_col=\"fnames\",\n",
    "      y_col=\"labels\",\n",
    "      batch_size=32,\n",
    "      seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"categorical\",\n",
    "      classes=labels,\n",
    "      target_size=(100,100))\n",
    "\n",
    "\n",
    "\n",
    "valid_generator=test_datagen.flow_from_dataframe(\n",
    "      dataframe=val_df,\n",
    "      directory=\"./data/images\",\n",
    "      x_col=\"fnames\",\n",
    "      y_col=\"labels\",\n",
    "      batch_size=32,\n",
    "      seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"categorical\",\n",
    "      classes=labels,\n",
    "      target_size=(100,100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49c790a0-c070-46fc-a219-c03f065e41d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=df[1900:],\n",
    "      directory=\"./data/images\",\n",
    "      x_col=\"fnames\",\n",
    "      batch_size=1,\n",
    "      seed=42,\n",
    "      shuffle=False,\n",
    "      class_mode=None,\n",
    "      target_size=(100,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4403221-0e45-4cc5-9cc8-6e84aa7d76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(100,100,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(5, activation='sigmoid'))\n",
    "model.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69b861c-1472-444a-a2ee-c158e0a96e3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9323567d-93a3-4500-b39a-a00318629079",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d306d73-b624-46e9-aaa3-dbcca93dd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = (pred >0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a65ff-7ab7-4ec6-a745-bbf13c9c73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "labels = train_generator.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(label[index])\n",
    "    predictions.append(\",\".join(l))\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385e1fa-c041-40a3-ad3a-c47482ed3e96",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
