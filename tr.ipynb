{
 "cells": [
  {
   "cell_type": "raw",
   "id": "2b25b451-e7e8-476a-8910-cf745809ef08",
   "metadata": {},
   "source": [
    "get KR from image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "8f951d4e-51fb-4521-81cd-48eb1c5e2dc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "\"\"\"Import from keras_preprocessing not from keras.preprocessing, because Keras may or maynot contain the features discussed here depending upon when you read this article, until the keras_preprocessed library is updated in Keras use the github version.\"\"\"\n",
    "from keras_preprocessing.image import ImageDataGenerator\n",
    "from keras.layers import Dense, Activation, Flatten, Dropout, BatchNormalization\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras import regularizers, optimizers\n",
    "#from tensorflow.keras import optimizers #., optimizers\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "\n",
    "#Importing all the relevant library\n",
    "%matplotlib inline\n",
    "import h5py, os\n",
    "#from functions import transforms as T\n",
    "#from functions.subsample import MaskFunc\n",
    "from scipy.io import loadmat\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import glob\n",
    "#from functions import transforms as T \n",
    "#from functions.subsample import MaskFunc\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "cd8d08e5-d611-4b99-add9-02cc854a9ffa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data_path(train_data_path, val_data_path, test_data_path):\n",
    "    \"\"\" Go through each subset (training, validation) and list all \n",
    "    the file names, the file paths and the slices of subjects in the training and validation sets \n",
    "    \"\"\"\n",
    "\n",
    "    data_list = {}\n",
    "    train_val_test = ['train', 'val', 'test']\n",
    "    data_path = [train_data_path, val_data_path, test_data_path]\n",
    "      \n",
    "    for i in range(len(data_path)):\n",
    "\n",
    "        data_list[train_val_test[i]] = []\n",
    "        \n",
    "        which_data_path = data_path[i]\n",
    "        tr = 0\n",
    "        te = 0\n",
    "        alfa = 0\n",
    "        for fname in sorted(os.listdir(which_data_path + '/images')):\n",
    "            if fname != \".DS_Store\":\n",
    "\n",
    "            \n",
    "                subject_data_path = os.path.join(which_data_path + '/images', fname)\n",
    "                     \n",
    "                if not os.path.isfile(subject_data_path): continue \n",
    "            \n",
    "          #  im_frame = Image.open(subject_data_path)\n",
    "\n",
    "            #get information from text file\n",
    "            # this will return a tuple of root and extension\n",
    "                split_tup = os.path.splitext(fname)\n",
    "\n",
    "  \n",
    "            # extract the file name and extension\n",
    "                file_name = split_tup[0]\n",
    "                file_path = os.path.join(which_data_path + '/texts', file_name) + '.txt'\n",
    "                f = open(os.path.join(which_data_path + '/texts', file_name) + '.txt', 'r')\n",
    "                line = f.readlines()[1]\n",
    "            \n",
    "                fields = line.split(',')\n",
    "                tr = int(fields[0])\n",
    "                te = int(fields[1])\n",
    "                alfa = int(fields[2])\n",
    "                f.close()\n",
    "                \n",
    "            # the first 5 slices are mostly noise so it is better to exlude them\n",
    "                data_list[train_val_test[i]] += [(fname, tr)]\n",
    "    \n",
    "    return data_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "e859bb9f-fa84-4609-bf9e-e2decd504740",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_list = load_data_path (\"data/train\", \"data/val\", \"data/test\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "81e6528b-7dbc-44ca-86f3-810e789cba1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data_list['train']\n",
    "val_data = data_list['val']\n",
    "test_data = data_list['val']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "08aa5111-5a82-4237-ba6c-72ee17a69ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(train_data, columns=['fnames', 'labels'])\n",
    "train_df['labels']= train_df['labels'].astype(str)\n",
    "train_df['fnames']= train_df['fnames'].astype(str)\n",
    "val_df = pd.DataFrame(val_data, columns=['fnames', 'labels'])\n",
    "val_df['labels']= val_df['labels'].astype(str)\n",
    "val_df['fnames']= val_df['fnames'].astype(str)\n",
    "test_df = pd.DataFrame(test_data, columns=['fnames', 'labels'])\n",
    "test_df['labels']= test_df['labels'].astype(str)\n",
    "test_df['fnames']= test_df['fnames'].astype(str)\n",
    "labels = train_df.labels.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ce8641ab-96af-4fea-8b4e-2b4e38f108a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_class = len(labels)\n",
    "num_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "a3c7e74a-edb4-4d1a-b1f4-52addf03c259",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.describe of         fnames labels\n",
       "0        1.png      5\n",
       "1       10.png     12\n",
       "2      100.png     11\n",
       "3     1000.png     13\n",
       "4     1001.png     18\n",
       "...        ...    ...\n",
       "2995   995.png     19\n",
       "2996   996.png     14\n",
       "2997   997.png      9\n",
       "2998   998.png      3\n",
       "2999   999.png     16\n",
       "\n",
       "[3000 rows x 2 columns]>"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "beca63cc-5587-4daf-b728-00942ebfa873",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3000 validated image filenames belonging to 20 classes.\n",
      "Found 500 validated image filenames belonging to 20 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen=ImageDataGenerator(rescale=1./255.)\n",
    "test_datagen=ImageDataGenerator(rescale=1./255.)\n",
    "\n",
    "train_generator=datagen.flow_from_dataframe(\n",
    "      dataframe=train_df,\n",
    "      directory=\"./data/train/images/\",\n",
    "      x_col=\"fnames\",\n",
    "      y_col=\"labels\",\n",
    "      batch_size=64,\n",
    "      seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"categorical\",\n",
    "      target_size=(224,224))\n",
    "\n",
    "\n",
    "\n",
    "valid_generator=test_datagen.flow_from_dataframe(\n",
    "      dataframe=val_df,\n",
    "      directory=\"./data/val/images/\",\n",
    "      x_col=\"fnames\",\n",
    "      y_col=\"labels\",\n",
    "      batch_size=64,\n",
    "      seed=42,\n",
    "      shuffle=True,\n",
    "      class_mode=\"categorical\",\n",
    "     target_size=(224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "49c790a0-c070-46fc-a219-c03f065e41d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 validated image filenames.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/keras_preprocessing/image/dataframe_iterator.py:282: UserWarning: Found 100 invalid image filename(s) in x_col=\"fnames\". These filename(s) will be ignored.\n",
      "  .format(n_invalid, x_col)\n"
     ]
    }
   ],
   "source": [
    "test_generator=test_datagen.flow_from_dataframe(\n",
    "dataframe=test_df,\n",
    "      directory=\"./data/test/images\",\n",
    "      x_col=\"fnames\",\n",
    "      batch_size=1,\n",
    "      seed=42,\n",
    "      shuffle=False,\n",
    "      class_mode=None,\n",
    "      target_size=(224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "d4403221-0e45-4cc5-9cc8-6e84aa7d76e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), padding='same',\n",
    "                 input_shape=(224,224,3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(512))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(num_class, activation='sigmoid'))\n",
    "model.compile(tf.keras.optimizers.RMSprop(lr=0.001, decay=1e-6),loss=\"binary_crossentropy\",metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9d63df44-e3af-4efb-a3e8-0275e9925102",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_8\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_32 (Conv2D)           (None, 224, 224, 32)      896       \n",
      "_________________________________________________________________\n",
      "activation_40 (Activation)   (None, 224, 224, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_33 (Conv2D)           (None, 222, 222, 32)      9248      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 222, 222, 32)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_16 (MaxPooling (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "dropout_24 (Dropout)         (None, 111, 111, 32)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_34 (Conv2D)           (None, 111, 111, 64)      18496     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 111, 111, 64)      0         \n",
      "_________________________________________________________________\n",
      "conv2d_35 (Conv2D)           (None, 109, 109, 64)      36928     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 109, 109, 64)      0         \n",
      "_________________________________________________________________\n",
      "max_pooling2d_17 (MaxPooling (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "dropout_25 (Dropout)         (None, 54, 54, 64)        0         \n",
      "_________________________________________________________________\n",
      "flatten_8 (Flatten)          (None, 186624)            0         \n",
      "_________________________________________________________________\n",
      "dense_16 (Dense)             (None, 512)               95552000  \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_26 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_17 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dropout_27 (Dropout)         (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_18 (Dense)             (None, 20)                10260     \n",
      "=================================================================\n",
      "Total params: 95,890,484\n",
      "Trainable params: 95,890,484\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "e5ee260d-ecc7-46a5-988f-9ca7b092e3dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 20 #10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "f69b861c-1472-444a-a2ee-c158e0a96e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "46/46 [==============================] - 73147s 1625s/step - loss: 0.4378 - accuracy: 0.0535 - val_loss: 0.2148 - val_accuracy: 0.0469\n",
      "Epoch 2/20\n",
      "46/46 [==============================] - 7911s 156s/step - loss: 0.2176 - accuracy: 0.0498 - val_loss: 0.2077 - val_accuracy: 0.0558\n",
      "Epoch 3/20\n",
      "46/46 [==============================] - 249s 5s/step - loss: 0.2138 - accuracy: 0.0385 - val_loss: 0.2073 - val_accuracy: 0.0357\n",
      "Epoch 4/20\n",
      "46/46 [==============================] - 240s 5s/step - loss: 0.2112 - accuracy: 0.0452 - val_loss: 0.2029 - val_accuracy: 0.0536\n",
      "Epoch 5/20\n",
      "46/46 [==============================] - 232s 5s/step - loss: 0.2057 - accuracy: 0.0619 - val_loss: 0.2124 - val_accuracy: 0.0536\n",
      "Epoch 6/20\n",
      "46/46 [==============================] - 231s 5s/step - loss: 0.2054 - accuracy: 0.0529 - val_loss: 0.2023 - val_accuracy: 0.0536\n",
      "Epoch 7/20\n",
      "46/46 [==============================] - 234s 5s/step - loss: 0.2049 - accuracy: 0.0521 - val_loss: 0.2043 - val_accuracy: 0.0491\n",
      "Epoch 8/20\n",
      "46/46 [==============================] - 231s 5s/step - loss: 0.2039 - accuracy: 0.0425 - val_loss: 0.2047 - val_accuracy: 0.0580\n",
      "Epoch 9/20\n",
      "46/46 [==============================] - 231s 5s/step - loss: 0.2035 - accuracy: 0.0614 - val_loss: 0.2002 - val_accuracy: 0.0558\n",
      "Epoch 10/20\n",
      "46/46 [==============================] - 231s 5s/step - loss: 0.2030 - accuracy: 0.0436 - val_loss: 0.2100 - val_accuracy: 0.0513\n",
      "Epoch 11/20\n",
      "46/46 [==============================] - 231s 5s/step - loss: 0.2033 - accuracy: 0.0564 - val_loss: 0.2017 - val_accuracy: 0.0536\n",
      "Epoch 12/20\n",
      "46/46 [==============================] - 238s 5s/step - loss: 0.2028 - accuracy: 0.0530 - val_loss: 0.2007 - val_accuracy: 0.0536\n",
      "Epoch 13/20\n",
      "46/46 [==============================] - 249s 5s/step - loss: 0.2024 - accuracy: 0.0464 - val_loss: 0.1997 - val_accuracy: 0.0469\n",
      "Epoch 14/20\n",
      "46/46 [==============================] - 255s 6s/step - loss: 0.2014 - accuracy: 0.0607 - val_loss: 0.2001 - val_accuracy: 0.0580\n",
      "Epoch 15/20\n",
      "46/46 [==============================] - 256s 6s/step - loss: 0.2026 - accuracy: 0.0467 - val_loss: 0.2011 - val_accuracy: 0.0580\n",
      "Epoch 16/20\n",
      "46/46 [==============================] - 246s 5s/step - loss: 0.2019 - accuracy: 0.0522 - val_loss: 0.2025 - val_accuracy: 0.0469\n",
      "Epoch 17/20\n",
      "46/46 [==============================] - 254s 6s/step - loss: 0.2019 - accuracy: 0.0579 - val_loss: 0.1996 - val_accuracy: 0.0536\n",
      "Epoch 18/20\n",
      "46/46 [==============================] - 235s 5s/step - loss: 0.2013 - accuracy: 0.0667 - val_loss: 0.2004 - val_accuracy: 0.0446\n",
      "Epoch 19/20\n",
      "46/46 [==============================] - 234s 5s/step - loss: 0.2003 - accuracy: 0.0623 - val_loss: 0.1999 - val_accuracy: 0.0491\n",
      "Epoch 20/20\n",
      "46/46 [==============================] - 233s 5s/step - loss: 0.2003 - accuracy: 0.0478 - val_loss: 0.2004 - val_accuracy: 0.0625\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x7f987961f490>"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "STEP_SIZE_TRAIN=train_generator.n//train_generator.batch_size\n",
    "STEP_SIZE_VALID=valid_generator.n//valid_generator.batch_size\n",
    "STEP_SIZE_TEST=test_generator.n//test_generator.batch_size\n",
    "model.fit_generator(generator=train_generator,\n",
    "                    steps_per_epoch=STEP_SIZE_TRAIN,\n",
    "                    validation_data=valid_generator,\n",
    "                    validation_steps=STEP_SIZE_VALID,\n",
    "                    epochs=n_epochs\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "9323567d-93a3-4500-b39a-a00318629079",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/hoangvo/opt/anaconda3/envs/coursework/lib/python3.7/site-packages/tensorflow/python/keras/engine/training.py:1905: UserWarning: `Model.predict_generator` is deprecated and will be removed in a future version. Please use `Model.predict`, which supports generators.\n",
      "  warnings.warn('`Model.predict_generator` is deprecated and '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 22s 54ms/step\n"
     ]
    }
   ],
   "source": [
    "test_generator.reset()\n",
    "pred=model.predict_generator(test_generator,\n",
    "steps=STEP_SIZE_TEST,\n",
    "verbose=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55f169b3-9e88-43d7-9480-c17a80cb9e4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d306d73-b624-46e9-aaa3-dbcca93dd9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bool = (pred >0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392a65ff-7ab7-4ec6-a745-bbf13c9c73de",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions=[]\n",
    "labels = train_generator.class_indices\n",
    "labels = dict((v,k) for k,v in labels.items())\n",
    "for row in pred_bool:\n",
    "    l=[]\n",
    "    for index,cls in enumerate(row):\n",
    "        if cls:\n",
    "            l.append(label[index])\n",
    "    predictions.append(\",\".join(l))\n",
    "filenames=test_generator.filenames\n",
    "results=pd.DataFrame({\"Filename\":filenames,\n",
    "                      \"Predictions\":predictions})\n",
    "#results.to_csv(\"results.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385e1fa-c041-40a3-ad3a-c47482ed3e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "e5188a42-beef-4321-8a2d-621a591d1bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
    "from keras.applications.vgg16 import preprocess_input\n",
    "\n",
    "#load the image\n",
    "my_image = load_img('data/test/images/1.png', target_size=(224, 224))\n",
    "\n",
    "#preprocess the image\n",
    "my_image = img_to_array(my_image)\n",
    "my_image = my_image.reshape((1, my_image.shape[0], my_image.shape[1], my_image.shape[2]))\n",
    "my_image = preprocess_input(my_image)\n",
    "\n",
    "#make the prediction\n",
    "prediction = model.predict(my_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "be769dfd-b348-4067-bb46-276897728b5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the model\n",
    "filename2 = 'model_tr.h5' \n",
    "model.save(filename2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "607599c9-9b5d-44b2-a74a-95516d370e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "# load model\n",
    "model = load_model('model_tr.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f7ee92-f551-4097-8516-44371b5b0fe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
